<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="&#34;auto&#34;"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png"><link rel="icon" type="image/png" href="/img/favicon.ico"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="description" content="Upward, not Northward."><meta name="author" content="bleem"><meta name="keywords" content="漠然,bleem,mritd"><title>Kubernetes 1.10.1 集群搭建 - bleem</title><link rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="/lib/hint/hint.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/atom-one-dark.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_pf9vaxs7x7b.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css"><link rel="stylesheet" href="/css/main.css"><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="bleem" type="application/atom+xml"><link rel="alternate" href="/rss.xml" title="bleem" type="application/rss+xml"></head><body><header style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"> <a class="navbar-brand" href="/">&nbsp;<strong>bleem</strong>&nbsp;</a> <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item"><a class="nav-link" href="/friends/"><i class="iconfont icon-link-fill"></i> 友链</a></li><li class="nav-item" id="search-btn"> <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"> <a class="nav-link" href="javascript:">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div class="banner intro-2" id="background" parallax="true" style="background:url(/img/default.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="container page-header text-center fade-in-up"><span class="h2" id="subtitle"></span><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2018-04-19 16:19" pubdate>2018年4月19日 下午</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 7.9k 字</span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 130 分钟</span></div></div></div></div></div></header><main><div class="container-fluid"><div class="row"><div class="d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-md"><div class="container nopadding-md" id="board-ctn"><div class="py-5" id="board"><article class="post-content mx-auto" id="post"><h1 style="display:none">Kubernetes 1.10.1 集群搭建</h1><div class="markdown-body" id="post-body"><blockquote><p>年后比较忙，所以 1.9 也没去折腾(其实就是懒)，最近刚有点时间凑巧 1.10 发布；所以就折腾一下 1.10，感觉搭建配置没有太大变化，折腾了 2 天基本算是搞定了，这里记录一下搭建过程；本文用到的被 block 镜像已经上传至 <a href="https://pan.baidu.com/s/14W86QQ4qi8qn8JqaDMcC3g" target="_blank" rel="noopener">百度云</a> 密码: dy5p</p></blockquote><h3 id="一、环境准备"><a href="#一、环境准备" class="headerlink" title="一、环境准备"></a>一、环境准备</h3><p>目前搭建仍然采用 5 台虚拟机测试，基本环境如下</p><table><thead><tr><th>IP</th><th>Type</th><th>Docker</th><th>OS</th></tr></thead><tbody><tr><td>192.168.1.61</td><td>master、node、etcd</td><td>18.03.0-ce</td><td>ubuntu 16.04</td></tr><tr><td>192.168.1.62</td><td>master、node、etcd</td><td>18.03.0-ce</td><td>ubuntu 16.04</td></tr><tr><td>192.168.1.63</td><td>master、node、etcd</td><td>18.03.0-ce</td><td>ubuntu 16.04</td></tr><tr><td>192.168.1.64</td><td>node</td><td>18.03.0-ce</td><td>ubuntu 16.04</td></tr><tr><td>192.168.1.65</td><td>node</td><td>18.03.0-ce</td><td>ubuntu 16.04</td></tr></tbody></table><p><strong>搭建前请看完整篇文章后再操作，一些变更说明我放到后面了；还有为了尽可能的懒，也不用什么 rpm、deb 了，直接 <code>hyperkube</code> + <code>service</code> 配置，布吉岛 <code>hyperkube</code> 的请看 <a href="https://github.com/kubernetes/kubernetes/blob/master/cluster/images/hyperkube/README.md" target="_blank" rel="noopener">GitHub</a>；本篇文章基于一些小脚本搭建(懒)，所以不会写太详细的步骤，具体请参考 <a href="https://github.com/mritd/ktool" target="_blank" rel="noopener">仓库脚本</a>，如果想看更详细的每一步的作用可以参考以前的 1.7、1.8 的搭建文档</strong></p><h3 id="二、搭建-Etcd-集群"><a href="#二、搭建-Etcd-集群" class="headerlink" title="二、搭建 Etcd 集群"></a>二、搭建 Etcd 集群</h3><h4 id="2-1、安装-cfssl"><a href="#2-1、安装-cfssl" class="headerlink" title="2.1、安装 cfssl"></a>2.1、安装 cfssl</h4><p>说实话这个章节我不想写，但是考虑可能有人真的需要，所以还是写了一下；<strong>这个安装脚本使用的是我私人的 cdn，文件可能随时删除，想使用最新版本请自行从 <a href="https://github.com/cloudflare/cfssl" target="_blank" rel="noopener">Github</a> clone 并编译</strong></p><div class="hljs"><pre><code class="hljs sh">wget https://mritdftp.b0.upaiyun.com/cfssl/cfssl.tar.gz
tar -zxvf cfssl.tar.gz
mv cfssl cfssljson /usr/<span class="hljs-built_in">local</span>/bin
chmod +x /usr/<span class="hljs-built_in">local</span>/bin/cfssl /usr/<span class="hljs-built_in">local</span>/bin/cfssljson
rm -f cfssl.tar.gz</code></pre></div><h4 id="2-2、生成-Etcd-证书"><a href="#2-2、生成-Etcd-证书" class="headerlink" title="2.2、生成 Etcd 证书"></a>2.2、生成 Etcd 证书</h4><h5 id="etcd-csr-json"><a href="#etcd-csr-json" class="headerlink" title="etcd-csr.json"></a>etcd-csr.json</h5><div class="hljs"><pre><code class="hljs json">&#123;
  <span class="hljs-attr">"key"</span>: &#123;
    <span class="hljs-attr">"algo"</span>: <span class="hljs-string">"rsa"</span>,
    <span class="hljs-attr">"size"</span>: <span class="hljs-number">2048</span>
  &#125;,
  <span class="hljs-attr">"names"</span>: [
    &#123;
      <span class="hljs-attr">"O"</span>: <span class="hljs-string">"etcd"</span>,
      <span class="hljs-attr">"OU"</span>: <span class="hljs-string">"etcd Security"</span>,
      <span class="hljs-attr">"L"</span>: <span class="hljs-string">"Beijing"</span>,
      <span class="hljs-attr">"ST"</span>: <span class="hljs-string">"Beijing"</span>,
      <span class="hljs-attr">"C"</span>: <span class="hljs-string">"CN"</span>
    &#125;
  ],
  <span class="hljs-attr">"CN"</span>: <span class="hljs-string">"etcd"</span>,
  <span class="hljs-attr">"hosts"</span>: [
    <span class="hljs-string">"127.0.0.1"</span>,
    <span class="hljs-string">"localhost"</span>,
    <span class="hljs-string">"192.168.1.61"</span>,
    <span class="hljs-string">"192.168.1.62"</span>,
    <span class="hljs-string">"192.168.1.63"</span>
  ]
&#125;</code></pre></div><h5 id="etcd-gencert-json"><a href="#etcd-gencert-json" class="headerlink" title="etcd-gencert.json"></a>etcd-gencert.json</h5><div class="hljs"><pre><code class="hljs json">&#123;
  <span class="hljs-attr">"signing"</span>: &#123;
    <span class="hljs-attr">"default"</span>: &#123;
        <span class="hljs-attr">"usages"</span>: [
          <span class="hljs-string">"signing"</span>,
          <span class="hljs-string">"key encipherment"</span>,
          <span class="hljs-string">"server auth"</span>,
          <span class="hljs-string">"client auth"</span>
        ],
        <span class="hljs-attr">"expiry"</span>: <span class="hljs-string">"87600h"</span>
    &#125;
  &#125;
&#125;</code></pre></div><h5 id="etcd-root-ca-csr-json"><a href="#etcd-root-ca-csr-json" class="headerlink" title="etcd-root-ca-csr.json"></a>etcd-root-ca-csr.json</h5><div class="hljs"><pre><code class="hljs json">&#123;
  <span class="hljs-attr">"key"</span>: &#123;
    <span class="hljs-attr">"algo"</span>: <span class="hljs-string">"rsa"</span>,
    <span class="hljs-attr">"size"</span>: <span class="hljs-number">4096</span>
  &#125;,
  <span class="hljs-attr">"names"</span>: [
    &#123;
      <span class="hljs-attr">"O"</span>: <span class="hljs-string">"etcd"</span>,
      <span class="hljs-attr">"OU"</span>: <span class="hljs-string">"etcd Security"</span>,
      <span class="hljs-attr">"L"</span>: <span class="hljs-string">"Beijing"</span>,
      <span class="hljs-attr">"ST"</span>: <span class="hljs-string">"Beijing"</span>,
      <span class="hljs-attr">"C"</span>: <span class="hljs-string">"CN"</span>
    &#125;
  ],
  <span class="hljs-attr">"CN"</span>: <span class="hljs-string">"etcd-root-ca"</span>
&#125;</code></pre></div><h5 id="生成证书"><a href="#生成证书" class="headerlink" title="生成证书"></a>生成证书</h5><div class="hljs"><pre><code class="hljs sh">cfssl gencert --initca=<span class="hljs-literal">true</span> etcd-root-ca-csr.json | cfssljson --bare etcd-root-ca
cfssl gencert --ca etcd-root-ca.pem --ca-key etcd-root-ca-key.pem --config etcd-gencert.json etcd-csr.json | cfssljson --bare etcd</code></pre></div><p>生成后如下</p><p><img src="https://cdn.oss.link/markdown/81203.png" srcset="/img/loading.gif" alt="gen etcd certs"></p><h4 id="2-3、安装-Etcd"><a href="#2-3、安装-Etcd" class="headerlink" title="2.3、安装 Etcd"></a>2.3、安装 Etcd</h4><p>Etcd 这里采用最新的 3.2.18 版本，安装方式直接复制二进制文件、systemd service 配置即可，不过需要注意相关用户权限问题，以下脚本配置等参考了 etcd rpm 安装包</p><h5 id="etcd-service"><a href="#etcd-service" class="headerlink" title="etcd.service"></a>etcd.service</h5><div class="hljs"><pre><code class="hljs sh">[Unit]
Description=Etcd Server
After=network.target
After=network-online.target
Wants=network-online.target

[Service]
Type=notify
WorkingDirectory=/var/lib/etcd/
EnvironmentFile=-/etc/etcd/etcd.conf
User=etcd
<span class="hljs-comment"># set GOMAXPROCS to number of processors</span>
ExecStart=/bin/bash -c <span class="hljs-string">"GOMAXPROCS=<span class="hljs-variable">$(nproc)</span> /usr/local/bin/etcd --name=\"<span class="hljs-variable">$&#123;ETCD_NAME&#125;</span>\" --data-dir=\"<span class="hljs-variable">$&#123;ETCD_DATA_DIR&#125;</span>\" --listen-client-urls=\"<span class="hljs-variable">$&#123;ETCD_LISTEN_CLIENT_URLS&#125;</span>\""</span>
Restart=on-failure
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target</code></pre></div><h5 id="etcd-conf"><a href="#etcd-conf" class="headerlink" title="etcd.conf"></a>etcd.conf</h5><div class="hljs"><pre><code class="hljs sh"><span class="hljs-comment"># [member]</span>
ETCD_NAME=etcd1
ETCD_DATA_DIR=<span class="hljs-string">"/var/lib/etcd/etcd1.etcd"</span>
ETCD_WAL_DIR=<span class="hljs-string">"/var/lib/etcd/wal"</span>
ETCD_SNAPSHOT_COUNT=<span class="hljs-string">"100"</span>
ETCD_HEARTBEAT_INTERVAL=<span class="hljs-string">"100"</span>
ETCD_ELECTION_TIMEOUT=<span class="hljs-string">"1000"</span>
ETCD_LISTEN_PEER_URLS=<span class="hljs-string">"https://192.168.1.61:2380"</span>
ETCD_LISTEN_CLIENT_URLS=<span class="hljs-string">"https://192.168.1.61:2379,http://127.0.0.1:2379"</span>
ETCD_MAX_SNAPSHOTS=<span class="hljs-string">"5"</span>
ETCD_MAX_WALS=<span class="hljs-string">"5"</span>
<span class="hljs-comment">#ETCD_CORS=""</span>

<span class="hljs-comment"># [cluster]</span>
ETCD_INITIAL_ADVERTISE_PEER_URLS=<span class="hljs-string">"https://192.168.1.61:2380"</span>
<span class="hljs-comment"># if you use different ETCD_NAME (e.g. test), set ETCD_INITIAL_CLUSTER value for this name, i.e. "test=http://..."</span>
ETCD_INITIAL_CLUSTER=<span class="hljs-string">"etcd1=https://192.168.1.61:2380,etcd2=https://192.168.1.62:2380,etcd3=https://192.168.1.63:2380"</span>
ETCD_INITIAL_CLUSTER_STATE=<span class="hljs-string">"new"</span>
ETCD_INITIAL_CLUSTER_TOKEN=<span class="hljs-string">"etcd-cluster"</span>
ETCD_ADVERTISE_CLIENT_URLS=<span class="hljs-string">"https://192.168.1.61:2379"</span>
<span class="hljs-comment">#ETCD_DISCOVERY=""</span>
<span class="hljs-comment">#ETCD_DISCOVERY_SRV=""</span>
<span class="hljs-comment">#ETCD_DISCOVERY_FALLBACK="proxy"</span>
<span class="hljs-comment">#ETCD_DISCOVERY_PROXY=""</span>
<span class="hljs-comment">#ETCD_STRICT_RECONFIG_CHECK="false"</span>
<span class="hljs-comment">#ETCD_AUTO_COMPACTION_RETENTION="0"</span>

<span class="hljs-comment"># [proxy]</span>
<span class="hljs-comment">#ETCD_PROXY="off"</span>
<span class="hljs-comment">#ETCD_PROXY_FAILURE_WAIT="5000"</span>
<span class="hljs-comment">#ETCD_PROXY_REFRESH_INTERVAL="30000"</span>
<span class="hljs-comment">#ETCD_PROXY_DIAL_TIMEOUT="1000"</span>
<span class="hljs-comment">#ETCD_PROXY_WRITE_TIMEOUT="5000"</span>
<span class="hljs-comment">#ETCD_PROXY_READ_TIMEOUT="0"</span>

<span class="hljs-comment"># [security]</span>
ETCD_CERT_FILE=<span class="hljs-string">"/etc/etcd/ssl/etcd.pem"</span>
ETCD_KEY_FILE=<span class="hljs-string">"/etc/etcd/ssl/etcd-key.pem"</span>
ETCD_CLIENT_CERT_AUTH=<span class="hljs-string">"true"</span>
ETCD_TRUSTED_CA_FILE=<span class="hljs-string">"/etc/etcd/ssl/etcd-root-ca.pem"</span>
ETCD_AUTO_TLS=<span class="hljs-string">"true"</span>
ETCD_PEER_CERT_FILE=<span class="hljs-string">"/etc/etcd/ssl/etcd.pem"</span>
ETCD_PEER_KEY_FILE=<span class="hljs-string">"/etc/etcd/ssl/etcd-key.pem"</span>
ETCD_PEER_CLIENT_CERT_AUTH=<span class="hljs-string">"true"</span>
ETCD_PEER_TRUSTED_CA_FILE=<span class="hljs-string">"/etc/etcd/ssl/etcd-root-ca.pem"</span>
ETCD_PEER_AUTO_TLS=<span class="hljs-string">"true"</span>

<span class="hljs-comment"># [logging]</span>
<span class="hljs-comment">#ETCD_DEBUG="false"</span>
<span class="hljs-comment"># examples for -log-package-levels etcdserver=WARNING,security=DEBUG</span>
<span class="hljs-comment">#ETCD_LOG_PACKAGE_LEVELS=""</span></code></pre></div><h5 id="install-sh"><a href="#install-sh" class="headerlink" title="install.sh"></a>install.sh</h5><div class="hljs"><pre><code class="hljs sh"><span class="hljs-meta">#!/bin/bash</span>

<span class="hljs-built_in">set</span> -e

ETCD_VERSION=<span class="hljs-string">"3.2.18"</span>

<span class="hljs-keyword">function</span> <span class="hljs-function"><span class="hljs-title">download</span></span>()&#123;
    <span class="hljs-keyword">if</span> [ ! -f <span class="hljs-string">"etcd-v<span class="hljs-variable">$&#123;ETCD_VERSION&#125;</span>-linux-amd64.tar.gz"</span> ]; <span class="hljs-keyword">then</span>
        wget https://github.com/coreos/etcd/releases/download/v<span class="hljs-variable">$&#123;ETCD_VERSION&#125;</span>/etcd-v<span class="hljs-variable">$&#123;ETCD_VERSION&#125;</span>-linux-amd64.tar.gz
        tar -zxvf etcd-v<span class="hljs-variable">$&#123;ETCD_VERSION&#125;</span>-linux-amd64.tar.gz
    <span class="hljs-keyword">fi</span>
&#125;

<span class="hljs-keyword">function</span> <span class="hljs-function"><span class="hljs-title">preinstall</span></span>()&#123;
    getent group etcd &gt;/dev/null || groupadd -r etcd
    getent passwd etcd &gt;/dev/null || useradd -r -g etcd -d /var/lib/etcd -s /sbin/nologin -c <span class="hljs-string">"etcd user"</span> etcd
&#125;

<span class="hljs-keyword">function</span> <span class="hljs-function"><span class="hljs-title">install</span></span>()&#123;
    <span class="hljs-built_in">echo</span> -e <span class="hljs-string">"\033[32mINFO: Copy etcd...\033[0m"</span>
    tar -zxvf etcd-v<span class="hljs-variable">$&#123;ETCD_VERSION&#125;</span>-linux-amd64.tar.gz
    cp etcd-v<span class="hljs-variable">$&#123;ETCD_VERSION&#125;</span>-linux-amd64/etcd* /usr/<span class="hljs-built_in">local</span>/bin
    rm -rf etcd-v<span class="hljs-variable">$&#123;ETCD_VERSION&#125;</span>-linux-amd64

    <span class="hljs-built_in">echo</span> -e <span class="hljs-string">"\033[32mINFO: Copy etcd config...\033[0m"</span>
    cp -r conf /etc/etcd
    chown -R etcd:etcd /etc/etcd
    chmod -R 755 /etc/etcd/ssl

    <span class="hljs-built_in">echo</span> -e <span class="hljs-string">"\033[32mINFO: Copy etcd systemd config...\033[0m"</span>
    cp systemd/*.service /lib/systemd/system
    systemctl daemon-reload
&#125;

<span class="hljs-keyword">function</span> <span class="hljs-function"><span class="hljs-title">postinstall</span></span>()&#123;
    <span class="hljs-keyword">if</span> [ ! -d <span class="hljs-string">"/var/lib/etcd"</span> ]; <span class="hljs-keyword">then</span>
        mkdir /var/lib/etcd
        chown -R etcd:etcd /var/lib/etcd
    <span class="hljs-keyword">fi</span>
&#125;


download
preinstall
install
postinstall</code></pre></div><p><strong>脚本解释如下:</strong></p><ul><li>download: 从 Github 下载二进制文件并解压</li><li>preinstall: 为 Etcd 安装做准备，创建 etcd 用户，并指定家目录登录 shell 等</li><li>install: 将 etcd 二进制文件复制到安装目录(<code>/usr/local/bin</code>)，复制 conf 目录到 <code>/etc/etcd</code></li><li>postinstall: 安装后收尾工作，比如检测 <code>/var/lib/etcd</code> 是否存在，纠正权限等</li></ul><p>整体目录结构如下</p><div class="hljs"><pre><code class="hljs sh">etcd
├── conf
│   ├── etcd.conf
│   └── ssl
│       ├── etcd.csr
│       ├── etcd-csr.json
│       ├── etcd-gencert.json
│       ├── etcd-key.pem
│       ├── etcd.pem
│       ├── etcd-root-ca.csr
│       ├── etcd-root-ca-csr.json
│       ├── etcd-root-ca-key.pem
│       └── etcd-root-ca.pem
├── etcd.service
└── install.sh</code></pre></div><p><strong>请自行创建 conf 目录等，并放置好相关文件，保存上面脚本为 <code>install.sh</code>，直接执行即可；在每台机器上更改好对应的配置，如 etcd 名称等，etcd 估计都是轻车熟路了，这里不做过多阐述；安装后启动即可</strong></p><div class="hljs"><pre><code class="hljs sh">systemctl start etcd
systemctl <span class="hljs-built_in">enable</span> etcd</code></pre></div><p><strong>注意: 集群 etcd 要 3 个一起启动，集群模式下单个启动会卡半天最后失败，不要傻等；启动成功后测试如下</strong></p><div class="hljs"><pre><code class="hljs sh"><span class="hljs-built_in">export</span> ETCDCTL_API=3
etcdctl --cacert=/etc/etcd/ssl/etcd-root-ca.pem --cert=/etc/etcd/ssl/etcd.pem --key=/etc/etcd/ssl/etcd-key.pem --endpoints=https://192.168.1.61:2379,https://192.168.1.62:2379,https://192.168.1.63:2379 endpoint health</code></pre></div><p><img src="https://cdn.oss.link/markdown/ji94m.png" srcset="/img/loading.gif" alt="check etcd"></p><h3 id="三、安装-Kubernets-集群组件"><a href="#三、安装-Kubernets-集群组件" class="headerlink" title="三、安装 Kubernets 集群组件"></a>三、安装 Kubernets 集群组件</h3><blockquote><p><strong>注意：与以前文档不同的是，这次不依赖 rpm 等特定安装包，而是基于 hyperkube 二进制手动安装，每个节点都会同时安装 Master 与 Node 配置文件，具体作为 Master 还是 Node 取决于服务开启情况</strong></p></blockquote><h4 id="3-1、生成-Kubernetes-证书"><a href="#3-1、生成-Kubernetes-证书" class="headerlink" title="3.1、生成 Kubernetes 证书"></a>3.1、生成 Kubernetes 证书</h4><p>由于 kubelet 和 kube-proxy 用到的 kubeconfig 配置文件需要借助 kubectl 来生成，所以需要先安装一下 kubectl</p><div class="hljs"><pre><code class="hljs sh">wget https://storage.googleapis.com/kubernetes-release/release/v1.10.1/bin/linux/amd64/hyperkube -O hyperkube_1.10.1
chmod +x hyperkube_1.10.1
cp hyperkube_1.10.1 /usr/<span class="hljs-built_in">local</span>/bin/hyperkube
ln -s /usr/<span class="hljs-built_in">local</span>/bin/hyperkube /usr/<span class="hljs-built_in">local</span>/bin/kubectl</code></pre></div><h5 id="admin-csr-json"><a href="#admin-csr-json" class="headerlink" title="admin-csr.json"></a>admin-csr.json</h5><div class="hljs"><pre><code class="hljs json">&#123;
  <span class="hljs-attr">"CN"</span>: <span class="hljs-string">"admin"</span>,
  <span class="hljs-attr">"hosts"</span>: [],
  <span class="hljs-attr">"key"</span>: &#123;
    <span class="hljs-attr">"algo"</span>: <span class="hljs-string">"rsa"</span>,
    <span class="hljs-attr">"size"</span>: <span class="hljs-number">2048</span>
  &#125;,
  <span class="hljs-attr">"names"</span>: [
    &#123;
      <span class="hljs-attr">"C"</span>: <span class="hljs-string">"CN"</span>,
      <span class="hljs-attr">"ST"</span>: <span class="hljs-string">"BeiJing"</span>,
      <span class="hljs-attr">"L"</span>: <span class="hljs-string">"BeiJing"</span>,
      <span class="hljs-attr">"O"</span>: <span class="hljs-string">"system:masters"</span>,
      <span class="hljs-attr">"OU"</span>: <span class="hljs-string">"System"</span>
    &#125;
  ]
&#125;</code></pre></div><h5 id="k8s-gencert-json"><a href="#k8s-gencert-json" class="headerlink" title="k8s-gencert.json"></a>k8s-gencert.json</h5><div class="hljs"><pre><code class="hljs json">&#123;
  <span class="hljs-attr">"signing"</span>: &#123;
    <span class="hljs-attr">"default"</span>: &#123;
      <span class="hljs-attr">"expiry"</span>: <span class="hljs-string">"87600h"</span>
    &#125;,
    <span class="hljs-attr">"profiles"</span>: &#123;
      <span class="hljs-attr">"kubernetes"</span>: &#123;
        <span class="hljs-attr">"usages"</span>: [
            <span class="hljs-string">"signing"</span>,
            <span class="hljs-string">"key encipherment"</span>,
            <span class="hljs-string">"server auth"</span>,
            <span class="hljs-string">"client auth"</span>
        ],
        <span class="hljs-attr">"expiry"</span>: <span class="hljs-string">"87600h"</span>
      &#125;
    &#125;
  &#125;
&#125;</code></pre></div><h5 id="k8s-root-ca-csr-json"><a href="#k8s-root-ca-csr-json" class="headerlink" title="k8s-root-ca-csr.json"></a>k8s-root-ca-csr.json</h5><div class="hljs"><pre><code class="hljs json">&#123;
  <span class="hljs-attr">"CN"</span>: <span class="hljs-string">"kubernetes"</span>,
  <span class="hljs-attr">"key"</span>: &#123;
    <span class="hljs-attr">"algo"</span>: <span class="hljs-string">"rsa"</span>,
    <span class="hljs-attr">"size"</span>: <span class="hljs-number">4096</span>
  &#125;,
  <span class="hljs-attr">"names"</span>: [
    &#123;
      <span class="hljs-attr">"C"</span>: <span class="hljs-string">"CN"</span>,
      <span class="hljs-attr">"ST"</span>: <span class="hljs-string">"BeiJing"</span>,
      <span class="hljs-attr">"L"</span>: <span class="hljs-string">"BeiJing"</span>,
      <span class="hljs-attr">"O"</span>: <span class="hljs-string">"k8s"</span>,
      <span class="hljs-attr">"OU"</span>: <span class="hljs-string">"System"</span>
    &#125;
  ]
&#125;</code></pre></div><h5 id="kube-apiserver-csr-json"><a href="#kube-apiserver-csr-json" class="headerlink" title="kube-apiserver-csr.json"></a>kube-apiserver-csr.json</h5><p><strong>注意: 在以前的文档中这个配置叫 <code>kubernetes-csr.json</code>，为了明确划分职责，这个证书目前被重命名以表示其专属于 <code>apiserver</code> 使用；加了一个 <code>*.kubernetes.master</code> 域名以便内部私有 DNS 解析使用(可删除)；至于很多人问过 <code>kubernetes</code> 这几个能不能删掉，答案是不可以的；因为当集群创建好后，default namespace 下会创建一个叫 <code>kubenretes</code> 的 svc，有一些组件会直接连接这个 svc 来跟 api 通讯的，证书如果不包含可能会出现无法连接的情况；其他几个 <code>kubernetes</code> 开头的域名作用相同</strong></p><div class="hljs"><pre><code class="hljs json">&#123;
    <span class="hljs-attr">"CN"</span>: <span class="hljs-string">"kubernetes"</span>,
    <span class="hljs-attr">"hosts"</span>: [
        <span class="hljs-string">"127.0.0.1"</span>,
        <span class="hljs-string">"10.254.0.1"</span>,
        <span class="hljs-string">"192.168.1.61"</span>,
        <span class="hljs-string">"192.168.1.62"</span>,
        <span class="hljs-string">"192.168.1.63"</span>,
        <span class="hljs-string">"192.168.1.64"</span>,
        <span class="hljs-string">"192.168.1.65"</span>,
        <span class="hljs-string">"*.kubernetes.master"</span>,
        <span class="hljs-string">"localhost"</span>,
        <span class="hljs-string">"kubernetes"</span>,
        <span class="hljs-string">"kubernetes.default"</span>,
        <span class="hljs-string">"kubernetes.default.svc"</span>,
        <span class="hljs-string">"kubernetes.default.svc.cluster"</span>,
        <span class="hljs-string">"kubernetes.default.svc.cluster.local"</span>
    ],
    <span class="hljs-attr">"key"</span>: &#123;
        <span class="hljs-attr">"algo"</span>: <span class="hljs-string">"rsa"</span>,
        <span class="hljs-attr">"size"</span>: <span class="hljs-number">2048</span>
    &#125;,
    <span class="hljs-attr">"names"</span>: [
        &#123;
            <span class="hljs-attr">"C"</span>: <span class="hljs-string">"CN"</span>,
            <span class="hljs-attr">"ST"</span>: <span class="hljs-string">"BeiJing"</span>,
            <span class="hljs-attr">"L"</span>: <span class="hljs-string">"BeiJing"</span>,
            <span class="hljs-attr">"O"</span>: <span class="hljs-string">"k8s"</span>,
            <span class="hljs-attr">"OU"</span>: <span class="hljs-string">"System"</span>
        &#125;
    ]
&#125;</code></pre></div><h5 id="kube-proxy-csr-json"><a href="#kube-proxy-csr-json" class="headerlink" title="kube-proxy-csr.json"></a>kube-proxy-csr.json</h5><div class="hljs"><pre><code class="hljs json">&#123;
  <span class="hljs-attr">"CN"</span>: <span class="hljs-string">"system:kube-proxy"</span>,
  <span class="hljs-attr">"hosts"</span>: [],
  <span class="hljs-attr">"key"</span>: &#123;
    <span class="hljs-attr">"algo"</span>: <span class="hljs-string">"rsa"</span>,
    <span class="hljs-attr">"size"</span>: <span class="hljs-number">2048</span>
  &#125;,
  <span class="hljs-attr">"names"</span>: [
    &#123;
      <span class="hljs-attr">"C"</span>: <span class="hljs-string">"CN"</span>,
      <span class="hljs-attr">"ST"</span>: <span class="hljs-string">"BeiJing"</span>,
      <span class="hljs-attr">"L"</span>: <span class="hljs-string">"BeiJing"</span>,
      <span class="hljs-attr">"O"</span>: <span class="hljs-string">"k8s"</span>,
      <span class="hljs-attr">"OU"</span>: <span class="hljs-string">"System"</span>
    &#125;
  ]
&#125;</code></pre></div><h5 id="生成证书及配置"><a href="#生成证书及配置" class="headerlink" title="生成证书及配置"></a>生成证书及配置</h5><div class="hljs"><pre><code class="hljs sh"><span class="hljs-comment"># 生成 CA</span>
cfssl gencert --initca=<span class="hljs-literal">true</span> k8s-root-ca-csr.json | cfssljson --bare k8s-root-ca

<span class="hljs-comment"># 依次生成其他组件证书</span>
<span class="hljs-keyword">for</span> targetName <span class="hljs-keyword">in</span> kube-apiserver admin kube-proxy; <span class="hljs-keyword">do</span>
    cfssl gencert --ca k8s-root-ca.pem --ca-key k8s-root-ca-key.pem --config k8s-gencert.json --profile kubernetes <span class="hljs-variable">$targetName</span>-csr.json | cfssljson --bare <span class="hljs-variable">$targetName</span>
<span class="hljs-keyword">done</span>

<span class="hljs-comment"># 地址默认为 127.0.0.1:6443</span>
<span class="hljs-comment"># 如果在 master 上启用 kubelet 请在生成后的 kubeconfig 中</span>
<span class="hljs-comment"># 修改该地址为 当前MASTER_IP:6443</span>
KUBE_APISERVER=<span class="hljs-string">"https://127.0.0.1:6443"</span>
BOOTSTRAP_TOKEN=$(head -c 16 /dev/urandom | od -An -t x | tr -d <span class="hljs-string">' '</span>)
<span class="hljs-built_in">echo</span> <span class="hljs-string">"Tokne: <span class="hljs-variable">$&#123;BOOTSTRAP_TOKEN&#125;</span>"</span>

<span class="hljs-comment"># 不要质疑 system:bootstrappers 用户组是否写错了，有疑问请参考官方文档</span>
<span class="hljs-comment"># https://kubernetes.io/docs/admin/kubelet-tls-bootstrapping/</span>
cat &gt; token.csv &lt;&lt;EOF
<span class="hljs-variable">$&#123;BOOTSTRAP_TOKEN&#125;</span>,kubelet-bootstrap,10001,<span class="hljs-string">"system:bootstrappers"</span>
EOF

<span class="hljs-built_in">echo</span> <span class="hljs-string">"Create kubelet bootstrapping kubeconfig..."</span>
<span class="hljs-comment"># 设置集群参数</span>
kubectl config <span class="hljs-built_in">set</span>-cluster kubernetes \
  --certificate-authority=k8s-root-ca.pem \
  --embed-certs=<span class="hljs-literal">true</span> \
  --server=<span class="hljs-variable">$&#123;KUBE_APISERVER&#125;</span> \
  --kubeconfig=bootstrap.kubeconfig
<span class="hljs-comment"># 设置客户端认证参数</span>
kubectl config <span class="hljs-built_in">set</span>-credentials kubelet-bootstrap \
  --token=<span class="hljs-variable">$&#123;BOOTSTRAP_TOKEN&#125;</span> \
  --kubeconfig=bootstrap.kubeconfig
<span class="hljs-comment"># 设置上下文参数</span>
kubectl config <span class="hljs-built_in">set</span>-context default \
  --cluster=kubernetes \
  --user=kubelet-bootstrap \
  --kubeconfig=bootstrap.kubeconfig
<span class="hljs-comment"># 设置默认上下文</span>
kubectl config use-context default --kubeconfig=bootstrap.kubeconfig

<span class="hljs-built_in">echo</span> <span class="hljs-string">"Create kube-proxy kubeconfig..."</span>
<span class="hljs-comment"># 设置集群参数</span>
kubectl config <span class="hljs-built_in">set</span>-cluster kubernetes \
  --certificate-authority=k8s-root-ca.pem \
  --embed-certs=<span class="hljs-literal">true</span> \
  --server=<span class="hljs-variable">$&#123;KUBE_APISERVER&#125;</span> \
  --kubeconfig=kube-proxy.kubeconfig
<span class="hljs-comment"># 设置客户端认证参数</span>
kubectl config <span class="hljs-built_in">set</span>-credentials kube-proxy \
  --client-certificate=kube-proxy.pem \
  --client-key=kube-proxy-key.pem \
  --embed-certs=<span class="hljs-literal">true</span> \
  --kubeconfig=kube-proxy.kubeconfig
<span class="hljs-comment"># 设置上下文参数</span>
kubectl config <span class="hljs-built_in">set</span>-context default \
  --cluster=kubernetes \
  --user=kube-proxy \
  --kubeconfig=kube-proxy.kubeconfig
<span class="hljs-comment"># 设置默认上下文</span>
kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig

<span class="hljs-comment"># 创建高级审计配置</span>
cat &gt;&gt; audit-policy.yaml &lt;&lt;EOF
<span class="hljs-comment"># Log all requests at the Metadata level.</span>
apiVersion: audit.k8s.io/v1beta1
kind: Policy
rules:
- level: Metadata
EOF</code></pre></div><p>生成后文件如下</p><p><img src="https://cdn.oss.link/markdown/xk8uj.png" srcset="/img/loading.gif" alt="k8s certs"></p><h4 id="3-2、准备-systemd-配置"><a href="#3-2、准备-systemd-配置" class="headerlink" title="3.2、准备 systemd 配置"></a>3.2、准备 systemd 配置</h4><p>所有组件的 <code>systemd</code> 配置如下</p><h5 id="kube-apiserver-service"><a href="#kube-apiserver-service" class="headerlink" title="kube-apiserver.service"></a>kube-apiserver.service</h5><div class="hljs"><pre><code class="hljs sh">[Unit]
Description=Kubernetes API Server
Documentation=https://github.com/GoogleCloudPlatform/kubernetes
After=network.target
After=etcd.service

[Service]
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/apiserver
User=kube
ExecStart=/usr/<span class="hljs-built_in">local</span>/bin/hyperkube apiserver \
            <span class="hljs-variable">$KUBE_LOGTOSTDERR</span> \
            <span class="hljs-variable">$KUBE_LOG_LEVEL</span> \
            <span class="hljs-variable">$KUBE_ETCD_SERVERS</span> \
            <span class="hljs-variable">$KUBE_API_ADDRESS</span> \
            <span class="hljs-variable">$KUBE_API_PORT</span> \
            <span class="hljs-variable">$KUBELET_PORT</span> \
            <span class="hljs-variable">$KUBE_ALLOW_PRIV</span> \
            <span class="hljs-variable">$KUBE_SERVICE_ADDRESSES</span> \
            <span class="hljs-variable">$KUBE_ADMISSION_CONTROL</span> \
            <span class="hljs-variable">$KUBE_API_ARGS</span>
Restart=on-failure
Type=notify
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target</code></pre></div><h5 id="kube-controller-manager-service"><a href="#kube-controller-manager-service" class="headerlink" title="kube-controller-manager.service"></a>kube-controller-manager.service</h5><div class="hljs"><pre><code class="hljs sh">[Unit]
Description=Kubernetes Controller Manager
Documentation=https://github.com/GoogleCloudPlatform/kubernetes

[Service]
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/controller-manager
User=kube
ExecStart=/usr/<span class="hljs-built_in">local</span>/bin/hyperkube controller-manager \
            <span class="hljs-variable">$KUBE_LOGTOSTDERR</span> \
            <span class="hljs-variable">$KUBE_LOG_LEVEL</span> \
            <span class="hljs-variable">$KUBE_MASTER</span> \
            <span class="hljs-variable">$KUBE_CONTROLLER_MANAGER_ARGS</span>
Restart=on-failure
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target</code></pre></div><h5 id="kubelet-service"><a href="#kubelet-service" class="headerlink" title="kubelet.service"></a>kubelet.service</h5><div class="hljs"><pre><code class="hljs sh">[Unit]
Description=Kubernetes Kubelet Server
Documentation=https://github.com/GoogleCloudPlatform/kubernetes
After=docker.service
Requires=docker.service

[Service]
WorkingDirectory=/var/lib/kubelet
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/kubelet
ExecStart=/usr/<span class="hljs-built_in">local</span>/bin/hyperkube kubelet \
            <span class="hljs-variable">$KUBE_LOGTOSTDERR</span> \
            <span class="hljs-variable">$KUBE_LOG_LEVEL</span> \
            <span class="hljs-variable">$KUBELET_API_SERVER</span> \
            <span class="hljs-variable">$KUBELET_ADDRESS</span> \
            <span class="hljs-variable">$KUBELET_PORT</span> \
            <span class="hljs-variable">$KUBELET_HOSTNAME</span> \
            <span class="hljs-variable">$KUBE_ALLOW_PRIV</span> \
            <span class="hljs-variable">$KUBELET_ARGS</span>
Restart=on-failure
KillMode=process

[Install]
WantedBy=multi-user.target</code></pre></div><h5 id="kube-proxy-service"><a href="#kube-proxy-service" class="headerlink" title="kube-proxy.service"></a>kube-proxy.service</h5><div class="hljs"><pre><code class="hljs sh">[Unit]
Description=Kubernetes Kube-Proxy Server
Documentation=https://github.com/GoogleCloudPlatform/kubernetes
After=network.target

[Service]
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/proxy
ExecStart=/usr/<span class="hljs-built_in">local</span>/bin/hyperkube proxy \
            <span class="hljs-variable">$KUBE_LOGTOSTDERR</span> \
            <span class="hljs-variable">$KUBE_LOG_LEVEL</span> \
            <span class="hljs-variable">$KUBE_MASTER</span> \
            <span class="hljs-variable">$KUBE_PROXY_ARGS</span>
Restart=on-failure
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target</code></pre></div><h5 id="kube-scheduler-service"><a href="#kube-scheduler-service" class="headerlink" title="kube-scheduler.service"></a>kube-scheduler.service</h5><div class="hljs"><pre><code class="hljs sh">[Unit]
Description=Kubernetes Scheduler Plugin
Documentation=https://github.com/GoogleCloudPlatform/kubernetes

[Service]
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/scheduler
User=kube
ExecStart=/usr/<span class="hljs-built_in">local</span>/bin/hyperkube scheduler \
            <span class="hljs-variable">$KUBE_LOGTOSTDERR</span> \
            <span class="hljs-variable">$KUBE_LOG_LEVEL</span> \
            <span class="hljs-variable">$KUBE_MASTER</span> \
            <span class="hljs-variable">$KUBE_SCHEDULER_ARGS</span>
Restart=on-failure
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target</code></pre></div><h4 id="3-3、Master-节点配置"><a href="#3-3、Master-节点配置" class="headerlink" title="3.3、Master 节点配置"></a>3.3、Master 节点配置</h4><p>Master 节点主要会运行 3 各组件: <code>kube-apiserver</code>、<code>kube-controller-manager</code>、<code>kube-scheduler</code>，其中用到的配置文件如下</p><h5 id="config"><a href="#config" class="headerlink" title="config"></a>config</h5><p><strong>config 是一个通用配置文件，值得注意的是由于安装时对于 Node、Master 节点都会包含该文件，在 Node 节点上请注释掉 <code>KUBE_MASTER</code> 变量，因为 Node 节点需要做 HA，要连接本地的 6443 加密端口；而这个变量将会覆盖 <code>kubeconfig</code> 中指定的 <code>127.0.0.1:6443</code> 地址</strong></p><div class="hljs"><pre><code class="hljs sh"><span class="hljs-comment">###</span>
<span class="hljs-comment"># kubernetes system config</span>
<span class="hljs-comment">#</span>
<span class="hljs-comment"># The following values are used to configure various aspects of all</span>
<span class="hljs-comment"># kubernetes services, including</span>
<span class="hljs-comment">#</span>
<span class="hljs-comment">#   kube-apiserver.service</span>
<span class="hljs-comment">#   kube-controller-manager.service</span>
<span class="hljs-comment">#   kube-scheduler.service</span>
<span class="hljs-comment">#   kubelet.service</span>
<span class="hljs-comment">#   kube-proxy.service</span>
<span class="hljs-comment"># logging to stderr means we get it in the systemd journal</span>
KUBE_LOGTOSTDERR=<span class="hljs-string">"--logtostderr=true"</span>

<span class="hljs-comment"># journal message level, 0 is debug</span>
KUBE_LOG_LEVEL=<span class="hljs-string">"--v=2"</span>

<span class="hljs-comment"># Should this cluster be allowed to run privileged docker containers</span>
KUBE_ALLOW_PRIV=<span class="hljs-string">"--allow-privileged=true"</span>

<span class="hljs-comment"># How the controller-manager, scheduler, and proxy find the apiserver</span>
KUBE_MASTER=<span class="hljs-string">"--master=http://127.0.0.1:8080"</span></code></pre></div><h5 id="apiserver"><a href="#apiserver" class="headerlink" title="apiserver"></a>apiserver</h5><p>apiserver 配置相对于 1.8 略有变动，其中准入控制器(<code>admission control</code>)选项名称变为了 <code>--enable-admission-plugins</code>，控制器列表也有相应变化，这里采用官方推荐配置，具体请参考 <a href="https://kubernetes.io/docs/admin/admission-controllers/#is-there-a-recommended-set-of-admission-controllers-to-use" target="_blank" rel="noopener">官方文档</a></p><div class="hljs"><pre><code class="hljs sh"><span class="hljs-comment">###</span>
<span class="hljs-comment"># kubernetes system config</span>
<span class="hljs-comment">#</span>
<span class="hljs-comment"># The following values are used to configure the kube-apiserver</span>
<span class="hljs-comment">#</span>

<span class="hljs-comment"># The address on the local server to listen to.</span>
KUBE_API_ADDRESS=<span class="hljs-string">"--advertise-address=192.168.1.61 --bind-address=192.168.1.61"</span>

<span class="hljs-comment"># The port on the local server to listen on.</span>
KUBE_API_PORT=<span class="hljs-string">"--secure-port=6443"</span>

<span class="hljs-comment"># Port minions listen on</span>
<span class="hljs-comment"># KUBELET_PORT="--kubelet-port=10250"</span>

<span class="hljs-comment"># Comma separated list of nodes in the etcd cluster</span>
KUBE_ETCD_SERVERS=<span class="hljs-string">"--etcd-servers=https://192.168.1.61:2379,https://192.168.1.62:2379,https://192.168.1.63:2379"</span>

<span class="hljs-comment"># Address range to use for services</span>
KUBE_SERVICE_ADDRESSES=<span class="hljs-string">"--service-cluster-ip-range=10.254.0.0/16"</span>

<span class="hljs-comment"># default admission control policies</span>
KUBE_ADMISSION_CONTROL=<span class="hljs-string">"--enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota,NodeRestriction"</span>

<span class="hljs-comment"># Add your own!</span>
KUBE_API_ARGS=<span class="hljs-string">" --anonymous-auth=false \</span>
<span class="hljs-string">                --apiserver-count=3 \</span>
<span class="hljs-string">                --audit-log-maxage=30 \</span>
<span class="hljs-string">                --audit-log-maxbackup=3 \</span>
<span class="hljs-string">                --audit-log-maxsize=100 \</span>
<span class="hljs-string">                --audit-log-path=/var/log/kube-audit/audit.log \</span>
<span class="hljs-string">                --audit-policy-file=/etc/kubernetes/audit-policy.yaml \</span>
<span class="hljs-string">                --authorization-mode=Node,RBAC \</span>
<span class="hljs-string">                --client-ca-file=/etc/kubernetes/ssl/k8s-root-ca.pem \</span>
<span class="hljs-string">                --enable-bootstrap-token-auth \</span>
<span class="hljs-string">                --enable-garbage-collector \</span>
<span class="hljs-string">                --enable-logs-handler \</span>
<span class="hljs-string">                --enable-swagger-ui \</span>
<span class="hljs-string">                --etcd-cafile=/etc/etcd/ssl/etcd-root-ca.pem \</span>
<span class="hljs-string">                --etcd-certfile=/etc/etcd/ssl/etcd.pem \</span>
<span class="hljs-string">                --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem \</span>
<span class="hljs-string">                --etcd-compaction-interval=5m0s \</span>
<span class="hljs-string">                --etcd-count-metric-poll-period=1m0s \</span>
<span class="hljs-string">                --event-ttl=48h0m0s \</span>
<span class="hljs-string">                --kubelet-https=true \</span>
<span class="hljs-string">                --kubelet-timeout=3s \</span>
<span class="hljs-string">                --log-flush-frequency=5s \</span>
<span class="hljs-string">                --token-auth-file=/etc/kubernetes/token.csv \</span>
<span class="hljs-string">                --tls-cert-file=/etc/kubernetes/ssl/kube-apiserver.pem \</span>
<span class="hljs-string">                --tls-private-key-file=/etc/kubernetes/ssl/kube-apiserver-key.pem \</span>
<span class="hljs-string">                --service-node-port-range=30000-50000 \</span>
<span class="hljs-string">                --service-account-key-file=/etc/kubernetes/ssl/k8s-root-ca.pem \</span>
<span class="hljs-string">                --storage-backend=etcd3 \</span>
<span class="hljs-string">                --enable-swagger-ui=true"</span></code></pre></div><h5 id="controller-manager"><a href="#controller-manager" class="headerlink" title="controller-manager"></a>controller-manager</h5><p>controller manager 配置默认开启了证书轮换能力用于自动签署 kueblet 证书，并且证书时间也设置了 10 年，可自行调整；增加了 <code>--controllers</code> 选项以指定开启全部控制器</p><div class="hljs"><pre><code class="hljs sh"><span class="hljs-comment">###</span>
<span class="hljs-comment"># The following values are used to configure the kubernetes controller-manager</span>

<span class="hljs-comment"># defaults from config and apiserver should be adequate</span>

<span class="hljs-comment"># Add your own!</span>
KUBE_CONTROLLER_MANAGER_ARGS=<span class="hljs-string">"  --bind-address=0.0.0.0 \</span>
<span class="hljs-string">                                --cluster-name=kubernetes \</span>
<span class="hljs-string">                                --cluster-signing-cert-file=/etc/kubernetes/ssl/k8s-root-ca.pem \</span>
<span class="hljs-string">                                --cluster-signing-key-file=/etc/kubernetes/ssl/k8s-root-ca-key.pem \</span>
<span class="hljs-string">                                --controllers=*,bootstrapsigner,tokencleaner \</span>
<span class="hljs-string">                                --deployment-controller-sync-period=10s \</span>
<span class="hljs-string">                                --experimental-cluster-signing-duration=86700h0m0s \</span>
<span class="hljs-string">                                --leader-elect=true \</span>
<span class="hljs-string">                                --node-monitor-grace-period=40s \</span>
<span class="hljs-string">                                --node-monitor-period=5s \</span>
<span class="hljs-string">                                --pod-eviction-timeout=5m0s \</span>
<span class="hljs-string">                                --terminated-pod-gc-threshold=50 \</span>
<span class="hljs-string">                                --root-ca-file=/etc/kubernetes/ssl/k8s-root-ca.pem \</span>
<span class="hljs-string">                                --service-account-private-key-file=/etc/kubernetes/ssl/k8s-root-ca-key.pem \</span>
<span class="hljs-string">                                --feature-gates=RotateKubeletServerCertificate=true"</span></code></pre></div><h5 id="scheduler"><a href="#scheduler" class="headerlink" title="scheduler"></a>scheduler</h5><div class="hljs"><pre><code class="hljs sh"><span class="hljs-comment">###</span>
<span class="hljs-comment"># kubernetes scheduler config</span>

<span class="hljs-comment"># default config should be adequate</span>

<span class="hljs-comment"># Add your own!</span>
KUBE_SCHEDULER_ARGS=<span class="hljs-string">"   --address=0.0.0.0 \</span>
<span class="hljs-string">                        --leader-elect=true \</span>
<span class="hljs-string">                        --algorithm-provider=DefaultProvider"</span></code></pre></div><h4 id="3-4、Node-节点配置"><a href="#3-4、Node-节点配置" class="headerlink" title="3.4、Node 节点配置"></a>3.4、Node 节点配置</h4><p>Node 节点上主要有 <code>kubelet</code>、<code>kube-proxy</code> 组件，用到的配置如下</p><h5 id="kubelet"><a href="#kubelet" class="headerlink" title="kubelet"></a>kubelet</h5><p>kubeket 默认也开启了证书轮换能力以保证自动续签相关证书，同时增加了 <code>--node-labels</code> 选项为 node 打一个标签，关于这个标签最后部分会有讨论，<strong>如果在 master 上启动 kubelet，请将 <code>node-role.kubernetes.io/k8s-node=true</code> 修改为 <code>node-role.kubernetes.io/k8s-master=true</code></strong></p><div class="hljs"><pre><code class="hljs sh"><span class="hljs-comment">###</span>
<span class="hljs-comment"># kubernetes kubelet (minion) config</span>

<span class="hljs-comment"># The address for the info server to serve on (set to 0.0.0.0 or "" for all interfaces)</span>
KUBELET_ADDRESS=<span class="hljs-string">"--node-ip=192.168.1.61"</span>

<span class="hljs-comment"># The port for the info server to serve on</span>
<span class="hljs-comment"># KUBELET_PORT="--port=10250"</span>

<span class="hljs-comment"># You may leave this blank to use the actual hostname</span>
KUBELET_HOSTNAME=<span class="hljs-string">"--hostname-override=k1.node"</span>

<span class="hljs-comment"># location of the api-server</span>
<span class="hljs-comment"># KUBELET_API_SERVER=""</span>

<span class="hljs-comment"># Add your own!</span>
KUBELET_ARGS=<span class="hljs-string">"  --bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig \</span>
<span class="hljs-string">                --cert-dir=/etc/kubernetes/ssl \</span>
<span class="hljs-string">                --cgroup-driver=cgroupfs \</span>
<span class="hljs-string">                --cluster-dns=10.254.0.2 \</span>
<span class="hljs-string">                --cluster-domain=cluster.local. \</span>
<span class="hljs-string">                --fail-swap-on=false \</span>
<span class="hljs-string">                --feature-gates=RotateKubeletClientCertificate=true,RotateKubeletServerCertificate=true \</span>
<span class="hljs-string">                --node-labels=node-role.kubernetes.io/k8s-node=true \</span>
<span class="hljs-string">                --image-gc-high-threshold=70 \</span>
<span class="hljs-string">                --image-gc-low-threshold=50 \</span>
<span class="hljs-string">                --kube-reserved=cpu=500m,memory=512Mi,ephemeral-storage=1Gi \</span>
<span class="hljs-string">                --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \</span>
<span class="hljs-string">                --system-reserved=cpu=1000m,memory=1024Mi,ephemeral-storage=1Gi \</span>
<span class="hljs-string">                --serialize-image-pulls=false \</span>
<span class="hljs-string">                --sync-frequency=30s \</span>
<span class="hljs-string">                --pod-infra-container-image=k8s.gcr.io/pause-amd64:3.0 \</span>
<span class="hljs-string">                --resolv-conf=/etc/resolv.conf \</span>
<span class="hljs-string">                --rotate-certificates"</span></code></pre></div><h5 id="proxy"><a href="#proxy" class="headerlink" title="proxy"></a>proxy</h5><div class="hljs"><pre><code class="hljs sh"><span class="hljs-comment">###</span>
<span class="hljs-comment"># kubernetes proxy config</span>
<span class="hljs-comment"># default config should be adequate</span>
<span class="hljs-comment"># Add your own!</span>
KUBE_PROXY_ARGS=<span class="hljs-string">"--bind-address=0.0.0.0 \</span>
<span class="hljs-string">                 --hostname-override=k1.node \</span>
<span class="hljs-string">                 --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig \</span>
<span class="hljs-string">                 --cluster-cidr=10.254.0.0/16"</span></code></pre></div><h4 id="3-5、安装集群组件"><a href="#3-5、安装集群组件" class="headerlink" title="3.5、安装集群组件"></a>3.5、安装集群组件</h4><p>上面已经准备好了相关配置文件，接下来将这些配置文件组织成如下目录结构以便后续脚本安装</p><div class="hljs"><pre><code class="hljs sh">k8s
├── conf
│   ├── apiserver
│   ├── audit-policy.yaml
│   ├── bootstrap.kubeconfig
│   ├── config
│   ├── controller-manager
│   ├── kubelet
│   ├── kube-proxy.kubeconfig
│   ├── proxy
│   ├── scheduler
│   ├── ssl
│   │   ├── admin.csr
│   │   ├── admin-csr.json
│   │   ├── admin-key.pem
│   │   ├── admin.pem
│   │   ├── k8s-gencert.json
│   │   ├── k8s-root-ca.csr
│   │   ├── k8s-root-ca-csr.json
│   │   ├── k8s-root-ca-key.pem
│   │   ├── k8s-root-ca.pem
│   │   ├── kube-apiserver.csr
│   │   ├── kube-apiserver-csr.json
│   │   ├── kube-apiserver-key.pem
│   │   ├── kube-apiserver.pem
│   │   ├── kube-proxy.csr
│   │   ├── kube-proxy-csr.json
│   │   ├── kube-proxy-key.pem
│   │   └── kube-proxy.pem
│   └── token.csv
├── hyperkube_1.10.1
├── install.sh
└── systemd
    ├── kube-apiserver.service
    ├── kube-controller-manager.service
    ├── kubelet.service
    ├── kube-proxy.service
    └── kube-scheduler.service</code></pre></div><p>其中 <code>install.sh</code> 内容如下</p><div class="hljs"><pre><code class="hljs sh"><span class="hljs-meta">#!/bin/bash</span>

<span class="hljs-built_in">set</span> -e

KUBE_VERSION=<span class="hljs-string">"1.10.1"</span>

<span class="hljs-keyword">function</span> <span class="hljs-function"><span class="hljs-title">download_k8s</span></span>()&#123;
    <span class="hljs-keyword">if</span> [ ! -f <span class="hljs-string">"hyperkube_<span class="hljs-variable">$&#123;KUBE_VERSION&#125;</span>"</span> ]; <span class="hljs-keyword">then</span>
        wget https://storage.googleapis.com/kubernetes-release/release/v<span class="hljs-variable">$&#123;KUBE_VERSION&#125;</span>/bin/linux/amd64/hyperkube -O hyperkube_<span class="hljs-variable">$&#123;KUBE_VERSION&#125;</span>
        chmod +x hyperkube_<span class="hljs-variable">$&#123;KUBE_VERSION&#125;</span>
    <span class="hljs-keyword">fi</span>
&#125;

<span class="hljs-keyword">function</span> <span class="hljs-function"><span class="hljs-title">preinstall</span></span>()&#123;
    getent group kube &gt;/dev/null || groupadd -r kube
    getent passwd kube &gt;/dev/null || useradd -r -g kube -d / -s /sbin/nologin -c <span class="hljs-string">"Kubernetes user"</span> kube
&#125;

<span class="hljs-keyword">function</span> <span class="hljs-function"><span class="hljs-title">install_k8s</span></span>()&#123;
    <span class="hljs-built_in">echo</span> -e <span class="hljs-string">"\033[32mINFO: Copy hyperkube...\033[0m"</span>
    cp hyperkube_<span class="hljs-variable">$&#123;KUBE_VERSION&#125;</span> /usr/<span class="hljs-built_in">local</span>/bin/hyperkube

    <span class="hljs-built_in">echo</span> -e <span class="hljs-string">"\033[32mINFO: Create symbolic link...\033[0m"</span>
    ln -sf /usr/<span class="hljs-built_in">local</span>/bin/hyperkube /usr/<span class="hljs-built_in">local</span>/bin/kubectl

    <span class="hljs-built_in">echo</span> -e <span class="hljs-string">"\033[32mINFO: Copy kubernetes config...\033[0m"</span>
    cp -r conf /etc/kubernetes
    <span class="hljs-keyword">if</span> [ -d <span class="hljs-string">"/etc/kubernetes/ssl"</span> ]; <span class="hljs-keyword">then</span>
        chown -R kube:kube /etc/kubernetes/ssl
    <span class="hljs-keyword">fi</span>

    <span class="hljs-built_in">echo</span> -e <span class="hljs-string">"\033[32mINFO: Copy kubernetes systemd config...\033[0m"</span>
    cp systemd/*.service /lib/systemd/system
    systemctl daemon-reload
&#125;

<span class="hljs-keyword">function</span> <span class="hljs-function"><span class="hljs-title">postinstall</span></span>()&#123;
    <span class="hljs-keyword">if</span> [ ! -d <span class="hljs-string">"/var/log/kube-audit"</span> ]; <span class="hljs-keyword">then</span>
        mkdir /var/<span class="hljs-built_in">log</span>/kube-audit
    <span class="hljs-keyword">fi</span>

    <span class="hljs-keyword">if</span> [ ! -d <span class="hljs-string">"/var/lib/kubelet"</span> ]; <span class="hljs-keyword">then</span>
        mkdir /var/lib/kubelet
    <span class="hljs-keyword">fi</span>

    <span class="hljs-keyword">if</span> [ ! -d <span class="hljs-string">"/usr/libexec"</span> ]; <span class="hljs-keyword">then</span>
        mkdir /usr/libexec
    <span class="hljs-keyword">fi</span>
    chown -R kube:kube /var/<span class="hljs-built_in">log</span>/kube-audit /var/lib/kubelet /usr/libexec
&#125;


download_k8s
preinstall
install_k8s
postinstall</code></pre></div><p><strong>脚本解释如下:</strong></p><ul><li>download_k8s: 下载 hyperkube 二进制文件</li><li>preinstall: 安装前处理，同 etcd 一样创建 kube 普通用户指定家目录、shell 等</li><li>install_k8s: 复制 hyperkube 到安装目录，为 kubectl 创建软连接(为啥创建软连接就能执行请自行阅读 <a href="https://github.com/kubernetes/kubernetes/blob/cce67ed8e7d461657d350a1cdd55791d1637fc43/cmd/hyperkube/main.go#L69" target="_blank" rel="noopener">源码</a>)，复制相关配置到对应目录，并处理权限</li><li>postinstall: 收尾工作，创建日志目录等，并处理权限</li></ul><p>最后执行此脚本安装即可，<strong>此外，应确保每个节点安装了 <code>ipset</code>、<code>conntrack</code> 两个包，因为 kube-proxy 组件会使用其处理 iptables 规则等</strong></p><h3 id="四、启动-Kubernetes-Master-节点"><a href="#四、启动-Kubernetes-Master-节点" class="headerlink" title="四、启动 Kubernetes Master 节点"></a>四、启动 Kubernetes Master 节点</h3><p>对于 <code>master</code> 节点启动无需做过多处理，多个 <code>master</code> 只要保证 <code>apiserver</code> 等配置中的 ip 地址监听没问题后直接启动即可</p><div class="hljs"><pre><code class="hljs sh">systemctl daemon-reload
systemctl start kube-apiserver
systemctl start kube-controller-manager
systemctl start kube-scheduler
systemctl <span class="hljs-built_in">enable</span> kube-apiserver
systemctl <span class="hljs-built_in">enable</span> kube-controller-manager
systemctl <span class="hljs-built_in">enable</span> kube-scheduler</code></pre></div><p>成功后截图如下</p><p><img src="https://cdn.oss.link/markdown/lqur1.png" srcset="/img/loading.gif" alt="Master success"></p><h3 id="五、启动-Kubernetes-Node-节点"><a href="#五、启动-Kubernetes-Node-节点" class="headerlink" title="五、启动 Kubernetes Node 节点"></a>五、启动 Kubernetes Node 节点</h3><p>由于 HA 等功能需要，对于 Node 需要做一些处理才能启动，主要有以下两个地方需要处理</p><h4 id="5-1、nginx-proxy"><a href="#5-1、nginx-proxy" class="headerlink" title="5.1、nginx-proxy"></a>5.1、nginx-proxy</h4><p>在启动 <code>kubelet</code>、<code>kube-proxy</code> 服务之前，需要在本地启动 <code>nginx</code> 来 tcp 负载均衡 <code>apiserver</code> 6443 端口，<code>nginx-proxy</code> 使用 <code>docker</code> + <code>systemd</code> 启动，配置如下</p><p><strong>注意: 对于在 master 节点启动 kubelet 来说，不需要 nginx 做负载均衡；可以跳过此步骤，并修改 <code>kubelet.kubeconfig</code>、<code>kube-proxy.kubeconfig</code> 中的 apiserver 地址为当前 master ip 6443 端口即可</strong></p><ul><li>nginx-proxy.service</li></ul><div class="hljs"><pre><code class="hljs sh">[Unit]
Description=kubernetes apiserver docker wrapper
Wants=docker.socket
After=docker.service

[Service]
User=root
PermissionsStartOnly=<span class="hljs-literal">true</span>
ExecStart=/usr/bin/docker run -p 127.0.0.1:6443:6443 \
                              -v /etc/nginx:/etc/nginx \
                              --name nginx-proxy \
                              --net=host \
                              --restart=on-failure:5 \
                              --memory=512M \
                              nginx:1.13.12-alpine
ExecStartPre=-/usr/bin/docker rm -f nginx-proxy
ExecStop=/usr/bin/docker stop nginx-proxy
Restart=always
RestartSec=15s
TimeoutStartSec=30s

[Install]
WantedBy=multi-user.target</code></pre></div><ul><li>nginx.conf</li></ul><div class="hljs"><pre><code class="hljs sh">error_log stderr notice;

worker_processes auto;
events &#123;
        multi_accept on;
        use epoll;
        worker_connections 1024;
&#125;

stream &#123;
    upstream kube_apiserver &#123;
        least_conn;
        server 192.168.1.61:6443;
        server 192.168.1.62:6443;
        server 192.168.1.63:6443;
    &#125;

    server &#123;
        listen        0.0.0.0:6443;
        proxy_pass    kube_apiserver;
        proxy_timeout 10m;
        proxy_connect_timeout 1s;
    &#125;
&#125;</code></pre></div><p><strong>启动 apiserver 的本地负载均衡</strong></p><div class="hljs"><pre><code class="hljs sh">mkdir /etc/nginx
cp nginx.conf /etc/nginx
cp nginx-proxy.service /lib/systemd/system

systemctl daemon-reload
systemctl start nginx-proxy
systemctl <span class="hljs-built_in">enable</span> nginx-proxy</code></pre></div><h4 id="5-2、TLS-bootstrapping"><a href="#5-2、TLS-bootstrapping" class="headerlink" title="5.2、TLS bootstrapping"></a>5.2、TLS bootstrapping</h4><p>创建好 <code>nginx-proxy</code> 后不要忘记为 <code>TLS Bootstrap</code> 创建相应的 <code>RBAC</code> 规则，这些规则能实现证自动签署 <code>TLS Bootstrap</code> 发出的 <code>CSR</code> 请求，从而实现证书轮换(创建一次即可)；详情请参考 <a href="https://mritd.me/2018/01/07/kubernetes-tls-bootstrapping-note/" target="_blank" rel="noopener">Kubernetes TLS bootstrapping 那点事</a></p><ul><li>tls-bootstrapping-clusterrole.yaml(与 1.8 一样)</li></ul><div class="hljs"><pre><code class="hljs yaml"><span class="hljs-comment"># A ClusterRole which instructs the CSR approver to approve a node requesting a</span>
<span class="hljs-comment"># serving cert matching its client cert.</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">ClusterRole</span>
<span class="hljs-attr">apiVersion:</span> <span class="hljs-string">rbac.authorization.k8s.io/v1</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">system:certificates.k8s.io:certificatesigningrequests:selfnodeserver</span>
<span class="hljs-attr">rules:</span>
<span class="hljs-bullet">-</span> <span class="hljs-attr">apiGroups:</span> <span class="hljs-string">["certificates.k8s.io"]</span>
  <span class="hljs-attr">resources:</span> <span class="hljs-string">["certificatesigningrequests/selfnodeserver"]</span>
  <span class="hljs-attr">verbs:</span> <span class="hljs-string">["create"]</span></code></pre></div><p><strong>在 master 执行创建</strong></p><div class="hljs"><pre><code class="hljs sh"><span class="hljs-comment"># 给与 kubelet-bootstrap 用户进行 node-bootstrapper 的权限</span>
kubectl create clusterrolebinding kubelet-bootstrap \
    --clusterrole=system:node-bootstrapper \
    --user=kubelet-bootstrap

kubectl create -f tls-bootstrapping-clusterrole.yaml

<span class="hljs-comment"># 自动批准 system:bootstrappers 组用户 TLS bootstrapping 首次申请证书的 CSR 请求</span>
kubectl create clusterrolebinding node-client-auto-approve-csr \
        --clusterrole=system:certificates.k8s.io:certificatesigningrequests:nodeclient \
        --group=system:bootstrappers

<span class="hljs-comment"># 自动批准 system:nodes 组用户更新 kubelet 自身与 apiserver 通讯证书的 CSR 请求</span>
kubectl create clusterrolebinding node-client-auto-renew-crt \
        --clusterrole=system:certificates.k8s.io:certificatesigningrequests:selfnodeclient \
        --group=system:nodes

<span class="hljs-comment"># 自动批准 system:nodes 组用户更新 kubelet 10250 api 端口证书的 CSR 请求</span>
kubectl create clusterrolebinding node-server-auto-renew-crt \
        --clusterrole=system:certificates.k8s.io:certificatesigningrequests:selfnodeserver \
        --group=system:nodes</code></pre></div><h4 id="5-3、执行启动"><a href="#5-3、执行启动" class="headerlink" title="5.3、执行启动"></a>5.3、执行启动</h4><p>多节点部署时先启动好 <code>nginx-proxy</code>，然后修改好相应配置的 ip 地址等配置，最终直接启动即可(master 上启动 kubelet 不要忘了修改 kubeconfig 中的 apiserver 地址，还有对应的 kubelet 的 node label)</p><div class="hljs"><pre><code class="hljs sh">systemctl daemon-reload
systemctl start kubelet
systemctl start kube-proxy
systemctl <span class="hljs-built_in">enable</span> kubelet
systemctl <span class="hljs-built_in">enable</span> kube-proxy</code></pre></div><p>最后启动成功后如下</p><p><img src="https://cdn.oss.link/markdown/r4s34.png" srcset="/img/loading.gif" alt="cluster started"></p><h3 id="五、安装-Calico"><a href="#五、安装-Calico" class="headerlink" title="五、安装 Calico"></a>五、安装 Calico</h3><p>Calico 安装仍然延续以前的方案，使用 Daemonset 安装 cni 组件，使用 systemd 控制 calico-node 以确保 calico-node 能正确的拿到主机名等</p><h4 id="5-1、修改-Calico-配置"><a href="#5-1、修改-Calico-配置" class="headerlink" title="5.1、修改 Calico 配置"></a>5.1、修改 Calico 配置</h4><div class="hljs"><pre><code class="hljs sh">wget https://docs.projectcalico.org/v3.1/getting-started/kubernetes/installation/hosted/calico.yaml -O calico.example.yaml

ETCD_CERT=`cat /etc/etcd/ssl/etcd.pem | base64 | tr -d <span class="hljs-string">'\n'</span>`
ETCD_KEY=`cat /etc/etcd/ssl/etcd-key.pem | base64 | tr -d <span class="hljs-string">'\n'</span>`
ETCD_CA=`cat /etc/etcd/ssl/etcd-root-ca.pem | base64 | tr -d <span class="hljs-string">'\n'</span>`
ETCD_ENDPOINTS=<span class="hljs-string">"https://192.168.1.61:2379,https://192.168.1.62:2379,https://192.168.1.63:2379"</span>

cp calico.example.yaml calico.yaml

sed -i <span class="hljs-string">"s@.*etcd_endpoints:.*@\ \ etcd_endpoints:\ \"<span class="hljs-variable">$&#123;ETCD_ENDPOINTS&#125;</span>\"@gi"</span> calico.yaml

sed -i <span class="hljs-string">"s@.*etcd-cert:.*@\ \ etcd-cert:\ <span class="hljs-variable">$&#123;ETCD_CERT&#125;</span>@gi"</span> calico.yaml
sed -i <span class="hljs-string">"s@.*etcd-key:.*@\ \ etcd-key:\ <span class="hljs-variable">$&#123;ETCD_KEY&#125;</span>@gi"</span> calico.yaml
sed -i <span class="hljs-string">"s@.*etcd-ca:.*@\ \ etcd-ca:\ <span class="hljs-variable">$&#123;ETCD_CA&#125;</span>@gi"</span> calico.yaml

sed -i <span class="hljs-string">'s@.*etcd_ca:.*@\ \ etcd_ca:\ "/calico-secrets/etcd-ca"@gi'</span> calico.yaml
sed -i <span class="hljs-string">'s@.*etcd_cert:.*@\ \ etcd_cert:\ "/calico-secrets/etcd-cert"@gi'</span> calico.yaml
sed -i <span class="hljs-string">'s@.*etcd_key:.*@\ \ etcd_key:\ "/calico-secrets/etcd-key"@gi'</span> calico.yaml

<span class="hljs-comment"># 注释掉 calico-node 部分(由 Systemd 接管)</span>
sed -i <span class="hljs-string">'123,219s@.*@#&amp;@gi'</span> calico.yaml</code></pre></div><h4 id="5-2、创建-Systemd-文件"><a href="#5-2、创建-Systemd-文件" class="headerlink" title="5.2、创建 Systemd 文件"></a>5.2、创建 Systemd 文件</h4><p><strong>注意: 创建 systemd service 配置文件要在每个节点上都执行</strong></p><div class="hljs"><pre><code class="hljs sh">K8S_MASTER_IP=<span class="hljs-string">"192.168.1.61"</span>
HOSTNAME=`cat /etc/hostname`
ETCD_ENDPOINTS=<span class="hljs-string">"https://192.168.1.61:2379,https://192.168.1.62:2379,https://192.168.1.63:2379"</span>

cat &gt; /lib/systemd/system/calico-node.service &lt;&lt;EOF
[Unit]
Description=calico node
After=docker.service
Requires=docker.service

[Service]
User=root
Environment=ETCD_ENDPOINTS=<span class="hljs-variable">$&#123;ETCD_ENDPOINTS&#125;</span>
PermissionsStartOnly=<span class="hljs-literal">true</span>
ExecStart=/usr/bin/docker run   --net=host --privileged --name=calico-node \\
                                -e ETCD_ENDPOINTS=\<span class="hljs-variable">$&#123;ETCD_ENDPOINTS&#125;</span> \\
                                -e ETCD_CA_CERT_FILE=/etc/etcd/ssl/etcd-root-ca.pem \\
                                -e ETCD_CERT_FILE=/etc/etcd/ssl/etcd.pem \\
                                -e ETCD_KEY_FILE=/etc/etcd/ssl/etcd-key.pem \\
                                -e NODENAME=<span class="hljs-variable">$&#123;HOSTNAME&#125;</span> \\
                                -e IP= \\
                                -e IP_AUTODETECTION_METHOD=can-reach=<span class="hljs-variable">$&#123;K8S_MASTER_IP&#125;</span> \\
                                -e AS=64512 \\
                                -e CLUSTER_TYPE=k8s,bgp \\
                                -e CALICO_IPV4POOL_CIDR=10.20.0.0/16 \\
                                -e CALICO_IPV4POOL_IPIP=always \\
                                -e CALICO_LIBNETWORK_ENABLED=<span class="hljs-literal">true</span> \\
                                -e CALICO_NETWORKING_BACKEND=bird \\
                                -e CALICO_DISABLE_FILE_LOGGING=<span class="hljs-literal">true</span> \\
                                -e FELIX_IPV6SUPPORT=<span class="hljs-literal">false</span> \\
                                -e FELIX_DEFAULTENDPOINTTOHOSTACTION=ACCEPT \\
                                -e FELIX_LOGSEVERITYSCREEN=info \\
                                -e FELIX_IPINIPMTU=1440 \\
                                -e FELIX_HEALTHENABLED=<span class="hljs-literal">true</span> \\
                                -e CALICO_K8S_NODE_REF=<span class="hljs-variable">$&#123;HOSTNAME&#125;</span> \\
                                -v /etc/calico/etcd-root-ca.pem:/etc/etcd/ssl/etcd-root-ca.pem \\
                                -v /etc/calico/etcd.pem:/etc/etcd/ssl/etcd.pem \\
                                -v /etc/calico/etcd-key.pem:/etc/etcd/ssl/etcd-key.pem \\
                                -v /lib/modules:/lib/modules \\
                                -v /var/lib/calico:/var/lib/calico \\
                                -v /var/run/calico:/var/run/calico \\
                                quay.io/calico/node:v3.1.0
ExecStop=/usr/bin/docker rm -f calico-node
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
EOF</code></pre></div><p><strong>对于以上脚本中的 <code>K8S_MASTER_IP</code> 变量，只需要填写一个 master ip 即可，这个变量用于 calico 自动选择 IP 使用；在宿主机有多张网卡的情况下，calcio node 会自动获取一个 IP，获取原则就是尝试是否能够联通这个 master ip</strong></p><p>由于 calico 需要使用 etcd 存储数据，所以需要复制 etcd 证书到相关目录，<strong><code>/etc/calico</code> 需要在每个节点都有</strong></p><div class="hljs"><pre><code class="hljs sh">cp -r /etc/etcd/ssl /etc/calico</code></pre></div><h4 id="5-3、修改-kubelet-配置"><a href="#5-3、修改-kubelet-配置" class="headerlink" title="5.3、修改 kubelet 配置"></a>5.3、修改 kubelet 配置</h4><p>使用 Calico 后需要修改 kubelet 配置增加 CNI 设置(<code>--network-plugin=cni</code>)，修改后配置如下</p><div class="hljs"><pre><code class="hljs sh"><span class="hljs-comment">###</span>
<span class="hljs-comment"># kubernetes kubelet (minion) config</span>

<span class="hljs-comment"># The address for the info server to serve on (set to 0.0.0.0 or "" for all interfaces)</span>
KUBELET_ADDRESS=<span class="hljs-string">"--node-ip=192.168.1.61"</span>

<span class="hljs-comment"># The port for the info server to serve on</span>
<span class="hljs-comment"># KUBELET_PORT="--port=10250"</span>

<span class="hljs-comment"># You may leave this blank to use the actual hostname</span>
KUBELET_HOSTNAME=<span class="hljs-string">"--hostname-override=k1.node"</span>

<span class="hljs-comment"># location of the api-server</span>
<span class="hljs-comment"># KUBELET_API_SERVER=""</span>

<span class="hljs-comment"># Add your own!</span>
KUBELET_ARGS=<span class="hljs-string">"  --bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig \</span>
<span class="hljs-string">                --cert-dir=/etc/kubernetes/ssl \</span>
<span class="hljs-string">                --cgroup-driver=cgroupfs \</span>
<span class="hljs-string">                --network-plugin=cni \</span>
<span class="hljs-string">                --cluster-dns=10.254.0.2 \</span>
<span class="hljs-string">                --cluster-domain=cluster.local. \</span>
<span class="hljs-string">                --fail-swap-on=false \</span>
<span class="hljs-string">                --feature-gates=RotateKubeletClientCertificate=true,RotateKubeletServerCertificate=true \</span>
<span class="hljs-string">                --node-labels=node-role.kubernetes.io/k8s-master=true \</span>
<span class="hljs-string">                --image-gc-high-threshold=70 \</span>
<span class="hljs-string">                --image-gc-low-threshold=50 \</span>
<span class="hljs-string">                --kube-reserved=cpu=500m,memory=512Mi,ephemeral-storage=1Gi \</span>
<span class="hljs-string">                --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \</span>
<span class="hljs-string">                --system-reserved=cpu=1000m,memory=1024Mi,ephemeral-storage=1Gi \</span>
<span class="hljs-string">                --serialize-image-pulls=false \</span>
<span class="hljs-string">                --sync-frequency=30s \</span>
<span class="hljs-string">                --pod-infra-container-image=k8s.gcr.io/pause-amd64:3.0 \</span>
<span class="hljs-string">                --resolv-conf=/etc/resolv.conf \</span>
<span class="hljs-string">                --rotate-certificates"</span></code></pre></div><h4 id="5-4、创建-Calico-Daemonset"><a href="#5-4、创建-Calico-Daemonset" class="headerlink" title="5.4、创建 Calico Daemonset"></a>5.4、创建 Calico Daemonset</h4><div class="hljs"><pre><code class="hljs sh"><span class="hljs-comment"># 先创建 RBAC</span>
kubectl apply -f \
https://docs.projectcalico.org/v3.1/getting-started/kubernetes/installation/rbac.yaml

<span class="hljs-comment"># 再创建 Calico Daemonset</span>
kubectl create -f calico.yaml</code></pre></div><h4 id="5-5、启动-Calico-Node"><a href="#5-5、启动-Calico-Node" class="headerlink" title="5.5、启动 Calico Node"></a>5.5、启动 Calico Node</h4><div class="hljs"><pre><code class="hljs sh">systemctl daemon-reload
systemctl restart calico-node
systemctl <span class="hljs-built_in">enable</span> calico-node

<span class="hljs-comment"># 等待 20s 拉取镜像</span>
sleep 20
systemctl restart kubelet</code></pre></div><h4 id="5-6、测试网络"><a href="#5-6、测试网络" class="headerlink" title="5.6、测试网络"></a>5.6、测试网络</h4><p>网络测试与其他几篇文章一样，创建几个 pod 测试即可</p><div class="hljs"><pre><code class="hljs sh"><span class="hljs-comment"># 创建 deployment</span>
cat &lt;&lt; EOF &gt;&gt; demo.deploy.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: demo-deployment
spec:
  replicas: 5
  selector:
    matchLabels:
      app: demo
  template:
    metadata:
      labels:
        app: demo
    spec:
      containers:
      - name: demo
        image: mritd/demo
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 80
EOF
kubectl create -f demo.deploy.yml</code></pre></div><p>测试结果如图所示</p><p><img src="https://cdn.oss.link/markdown/u9j3v.png" srcset="/img/loading.gif" alt="test calico"></p><h3 id="六、部署集群-DNS"><a href="#六、部署集群-DNS" class="headerlink" title="六、部署集群 DNS"></a>六、部署集群 DNS</h3><h4 id="6-1、部署-CoreDNS"><a href="#6-1、部署-CoreDNS" class="headerlink" title="6.1、部署 CoreDNS"></a>6.1、部署 CoreDNS</h4><p>CoreDNS 给出了标准的 deployment 配置，如下</p><ul><li>coredns.yaml.sed</li></ul><div class="hljs"><pre><code class="hljs sh">apiVersion: v1
kind: ServiceAccount
metadata:
  name: coredns
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
  name: system:coredns
rules:
- apiGroups:
  - <span class="hljs-string">""</span>
  resources:
  - endpoints
  - services
  - pods
  - namespaces
  verbs:
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  annotations:
    rbac.authorization.kubernetes.io/autoupdate: <span class="hljs-string">"true"</span>
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
  name: system:coredns
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:coredns
subjects:
- kind: ServiceAccount
  name: coredns
  namespace: kube-system
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: coredns
  namespace: kube-system
data:
  Corefile: |
    .:53 &#123;
        errors
        health
        kubernetes CLUSTER_DOMAIN REVERSE_CIDRS &#123;
          pods insecure
          upstream
          fallthrough <span class="hljs-keyword">in</span>-addr.arpa ip6.arpa
        &#125;
        prometheus :9153
        proxy . /etc/resolv.conf
        cache 30
    &#125;
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: coredns
  namespace: kube-system
  labels:
    k8s-app: kube-dns
    kubernetes.io/name: <span class="hljs-string">"CoreDNS"</span>
spec:
  replicas: 2
  strategy:
    <span class="hljs-built_in">type</span>: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  selector:
    matchLabels:
      k8s-app: kube-dns
  template:
    metadata:
      labels:
        k8s-app: kube-dns
    spec:
      serviceAccountName: coredns
      tolerations:
        - key: <span class="hljs-string">"CriticalAddonsOnly"</span>
          operator: <span class="hljs-string">"Exists"</span>
      containers:
      - name: coredns
        image: coredns/coredns:1.1.1
        imagePullPolicy: IfNotPresent
        args: [ <span class="hljs-string">"-conf"</span>, <span class="hljs-string">"/etc/coredns/Corefile"</span> ]
        volumeMounts:
        - name: config-volume
          mountPath: /etc/coredns
        ports:
        - containerPort: 53
          name: dns
          protocol: UDP
        - containerPort: 53
          name: dns-tcp
          protocol: TCP
        - containerPort: 9153
          name: metrics
          protocol: TCP
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 60
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 5
      dnsPolicy: Default
      volumes:
        - name: config-volume
          configMap:
            name: coredns
            items:
            - key: Corefile
              path: Corefile
---
apiVersion: v1
kind: Service
metadata:
  name: kube-dns
  namespace: kube-system
  annotations:
    prometheus.io/scrape: <span class="hljs-string">"true"</span>
  labels:
    k8s-app: kube-dns
    kubernetes.io/cluster-service: <span class="hljs-string">"true"</span>
    kubernetes.io/name: <span class="hljs-string">"CoreDNS"</span>
spec:
  selector:
    k8s-app: kube-dns
  clusterIP: CLUSTER_DNS_IP
  ports:
  - name: dns
    port: 53
    protocol: UDP
  - name: dns-tcp
    port: 53
    protocol: TCP</code></pre></div><p>然后直接使用脚本替换即可(脚本变量我已经修改了)</p><div class="hljs"><pre><code class="hljs sh"><span class="hljs-meta">#!/bin/bash</span>

<span class="hljs-comment"># Deploys CoreDNS to a cluster currently running Kube-DNS.</span>

SERVICE_CIDR=<span class="hljs-variable">$&#123;1:-10.254.0.0/16&#125;</span>
POD_CIDR=<span class="hljs-variable">$&#123;2:-10.20.0.0/16&#125;</span>
CLUSTER_DNS_IP=<span class="hljs-variable">$&#123;3:-10.254.0.2&#125;</span>
CLUSTER_DOMAIN=<span class="hljs-variable">$&#123;4:-cluster.local&#125;</span>
YAML_TEMPLATE=<span class="hljs-variable">$&#123;5:-`pwd`/coredns.yaml.sed&#125;</span>

sed -e s/CLUSTER_DNS_IP/<span class="hljs-variable">$CLUSTER_DNS_IP</span>/g -e s/CLUSTER_DOMAIN/<span class="hljs-variable">$CLUSTER_DOMAIN</span>/g -e s?SERVICE_CIDR?<span class="hljs-variable">$SERVICE_CIDR</span>?g -e s?POD_CIDR?<span class="hljs-variable">$POD_CIDR</span>?g <span class="hljs-variable">$YAML_TEMPLATE</span> &gt; coredns.yaml</code></pre></div><p>最后使用 <code>kubectl</code> 创建一下</p><div class="hljs"><pre><code class="hljs sh"><span class="hljs-comment"># 执行上面的替换脚本</span>
./deploy.sh

<span class="hljs-comment"># 创建 CoreDNS</span>
kubectl create -f coredns.yaml</code></pre></div><p>测试截图如下</p><p><img src="https://cdn.oss.link/markdown/v1jdc.png" srcset="/img/loading.gif" alt="test dns"></p><h4 id="6-2、部署-DNS-自动扩容"><a href="#6-2、部署-DNS-自动扩容" class="headerlink" title="6.2、部署 DNS 自动扩容"></a>6.2、部署 DNS 自动扩容</h4><p>自动扩容跟以往一样，yaml 创建一下就行</p><ul><li>dns-horizontal-autoscaler.yaml</li></ul><div class="hljs"><pre><code class="hljs sh"><span class="hljs-comment"># Copyright 2016 The Kubernetes Authors.</span>
<span class="hljs-comment">#</span>
<span class="hljs-comment"># Licensed under the Apache License, Version 2.0 (the "License");</span>
<span class="hljs-comment"># you may not use this file except in compliance with the License.</span>
<span class="hljs-comment"># You may obtain a copy of the License at</span>
<span class="hljs-comment">#</span>
<span class="hljs-comment">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="hljs-comment">#</span>
<span class="hljs-comment"># Unless required by applicable law or agreed to in writing, software</span>
<span class="hljs-comment"># distributed under the License is distributed on an "AS IS" BASIS,</span>
<span class="hljs-comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="hljs-comment"># See the License for the specific language governing permissions and</span>
<span class="hljs-comment"># limitations under the License.</span>

kind: ServiceAccount
apiVersion: v1
metadata:
  name: kube-dns-autoscaler
  namespace: kube-system
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: system:kube-dns-autoscaler
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
rules:
  - apiGroups: [<span class="hljs-string">""</span>]
    resources: [<span class="hljs-string">"nodes"</span>]
    verbs: [<span class="hljs-string">"list"</span>]
  - apiGroups: [<span class="hljs-string">""</span>]
    resources: [<span class="hljs-string">"replicationcontrollers/scale"</span>]
    verbs: [<span class="hljs-string">"get"</span>, <span class="hljs-string">"update"</span>]
  - apiGroups: [<span class="hljs-string">"extensions"</span>]
    resources: [<span class="hljs-string">"deployments/scale"</span>, <span class="hljs-string">"replicasets/scale"</span>]
    verbs: [<span class="hljs-string">"get"</span>, <span class="hljs-string">"update"</span>]
<span class="hljs-comment"># Remove the configmaps rule once below issue is fixed:</span>
<span class="hljs-comment"># kubernetes-incubator/cluster-proportional-autoscaler#16</span>
  - apiGroups: [<span class="hljs-string">""</span>]
    resources: [<span class="hljs-string">"configmaps"</span>]
    verbs: [<span class="hljs-string">"get"</span>, <span class="hljs-string">"create"</span>]
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: system:kube-dns-autoscaler
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
subjects:
  - kind: ServiceAccount
    name: kube-dns-autoscaler
    namespace: kube-system
roleRef:
  kind: ClusterRole
  name: system:kube-dns-autoscaler
  apiGroup: rbac.authorization.k8s.io

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kube-dns-autoscaler
  namespace: kube-system
  labels:
    k8s-app: kube-dns-autoscaler
    kubernetes.io/cluster-service: <span class="hljs-string">"true"</span>
    addonmanager.kubernetes.io/mode: Reconcile
spec:
  selector:
    matchLabels:
      k8s-app: kube-dns-autoscaler
  template:
    metadata:
      labels:
        k8s-app: kube-dns-autoscaler
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: <span class="hljs-string">''</span>
    spec:
      priorityClassName: system-cluster-critical
      containers:
      - name: autoscaler
        image: k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.1.2-r2
        resources:
            requests:
                cpu: <span class="hljs-string">"20m"</span>
                memory: <span class="hljs-string">"10Mi"</span>
        <span class="hljs-built_in">command</span>:
          - /cluster-proportional-autoscaler
          - --namespace=kube-system
          - --configmap=kube-dns-autoscaler
          <span class="hljs-comment"># Should keep target in sync with cluster/addons/dns/kube-dns.yaml.base</span>
          - --target=Deployment/kube-dns
          <span class="hljs-comment"># When cluster is using large nodes(with more cores), "coresPerReplica" should dominate.</span>
          <span class="hljs-comment"># If using small nodes, "nodesPerReplica" should dominate.</span>
          - --default-params=&#123;<span class="hljs-string">"linear"</span>:&#123;<span class="hljs-string">"coresPerReplica"</span>:256,<span class="hljs-string">"nodesPerReplica"</span>:16,<span class="hljs-string">"preventSinglePointFailure"</span>:<span class="hljs-literal">true</span>&#125;&#125;
          - --logtostderr=<span class="hljs-literal">true</span>
          - --v=2
      tolerations:
      - key: <span class="hljs-string">"CriticalAddonsOnly"</span>
        operator: <span class="hljs-string">"Exists"</span>
      serviceAccountName: kube-dns-autoscaler</code></pre></div><h3 id="七、部署-heapster"><a href="#七、部署-heapster" class="headerlink" title="七、部署 heapster"></a>七、部署 heapster</h3><p>heapster 部署相对简单的多，yaml 创建一下就可以了</p><div class="hljs"><pre><code class="hljs sh">kubectl create -f https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/influxdb/grafana.yaml
kubectl create -f https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/influxdb/heapster.yaml
kubectl create -f https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/influxdb/influxdb.yaml
kubectl create -f https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/rbac/heapster-rbac.yaml</code></pre></div><h3 id="八、部署-Dashboard"><a href="#八、部署-Dashboard" class="headerlink" title="八、部署 Dashboard"></a>八、部署 Dashboard</h3><h4 id="8-1、部署-Dashboard"><a href="#8-1、部署-Dashboard" class="headerlink" title="8.1、部署 Dashboard"></a>8.1、部署 Dashboard</h4><p>Dashboard 部署同 heapster 一样，不过为了方便访问，我设置了 NodePort，还注意到一点是 yaml 拉取策略已经没有比较傻的 <code>Always</code> 了</p><div class="hljs"><pre><code class="hljs sh">wget https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml -O kubernetes-dashboard.yaml</code></pre></div><p>将最后部分的端口暴露修改如下</p><div class="hljs"><pre><code class="hljs yaml"><span class="hljs-comment"># ------------------- Dashboard Service ------------------- #</span>

<span class="hljs-attr">kind:</span> <span class="hljs-string">Service</span>
<span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">labels:</span>
    <span class="hljs-attr">k8s-app:</span> <span class="hljs-string">kubernetes-dashboard</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">kubernetes-dashboard</span>
  <span class="hljs-attr">namespace:</span> <span class="hljs-string">kube-system</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">type:</span> <span class="hljs-string">NodePort</span>
  <span class="hljs-attr">ports:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">dashboard-tls</span>
      <span class="hljs-attr">port:</span> <span class="hljs-number">443</span>
      <span class="hljs-attr">targetPort:</span> <span class="hljs-number">8443</span>
      <span class="hljs-attr">nodePort:</span> <span class="hljs-number">30000</span>
      <span class="hljs-attr">protocol:</span> <span class="hljs-string">TCP</span>
  <span class="hljs-attr">selector:</span>
    <span class="hljs-attr">k8s-app:</span> <span class="hljs-string">kubernetes-dashboard</span></code></pre></div><p>然后执行 <code>kubectl create -f kubernetes-dashboard.yaml</code> 即可</p><h4 id="8-2、创建-admin-账户"><a href="#8-2、创建-admin-账户" class="headerlink" title="8.2、创建 admin 账户"></a>8.2、创建 admin 账户</h4><p>默认情况下部署成功后可以直接访问 <code>https://NODE_IP:30000</code> 访问，但是想要登录进去查看的话需要使用 kubeconfig 或者 access token 的方式；实际上这个就是 RBAC 授权控制，以下提供一个创建 admin access token 的脚本，更细节的权限控制比如只读用户可以参考 <a href="https://mritd.me/2018/03/20/use-rbac-to-control-kubectl-permissions/" target="_blank" rel="noopener">使用 RBAC 控制 kubectl 权限</a>，RBAC 权限控制原理是一样的</p><div class="hljs"><pre><code class="hljs sh"><span class="hljs-meta">#!/bin/bash</span>

<span class="hljs-keyword">if</span> kubectl get sa dashboard-admin -n kube-system &amp;&gt; /dev/null;<span class="hljs-keyword">then</span>
    <span class="hljs-built_in">echo</span> -e <span class="hljs-string">"\033[33mWARNING: ServiceAccount dashboard-admin exist!\033[0m"</span>
<span class="hljs-keyword">else</span>
    kubectl create sa dashboard-admin -n kube-system
    kubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin
<span class="hljs-keyword">fi</span>

kubectl describe secret -n kube-system $(kubectl get secrets -n kube-system | grep dashboard-admin | cut -f1 -d <span class="hljs-string">' '</span>) | grep -E <span class="hljs-string">'^token'</span></code></pre></div><p>将以上脚本保存为 <code>create_dashboard_sa.sh</code> 执行即可，成功后访问截图如下(<strong>如果访问不了的话请检查下 iptable FORWARD 默认规则是否为 DROP，如果是将其改为 ACCEPT 即可</strong>)</p><p><img src="https://cdn.oss.link/markdown/oxmms.png" srcset="/img/loading.gif" alt="create_dashboard_sa"></p><p><img src="https://cdn.oss.link/markdown/pyplb.png" srcset="/img/loading.gif" alt="dashboard"></p><h3 id="九、其他说明"><a href="#九、其他说明" class="headerlink" title="九、其他说明"></a>九、其他说明</h3><h4 id="9-1、选项-label-等说明"><a href="#9-1、选项-label-等说明" class="headerlink" title="9.1、选项 label 等说明"></a>9.1、选项 label 等说明</h4><p>部署过程中注意到一些选项已经做了名称更改，比如 <code>--network-plugin-dir</code> 变更为 <code>--cni-bin-dir</code> 等，具体的那些选项做了变更请自行对比配置，以及查看官方文档；</p><p>对于 Node label <code>--node-labels=node-role.kubernetes.io/k8s-node=true</code> 这个选项，它的作用只是在 <code>kubectl get node</code> 时 ROLES 栏显示是什么节点；不过需要注意 <strong>master 上的 kubelet 不要将 <code>node-role.kubernetes.io/k8s-master=true</code> 更改成 <code>node-role.kubernetes.io/master=xxxx</code>；后面这个 <code>node-role.kubernetes.io/master</code> 是 kubeadm 用的，这个 label 会告诉 k8s 调度器当前节点为 master，从而执行一些特定动作，比如 <code>node-role.kubernetes.io/master:NoSchedule</code> 此节点将不会被分配 pod；具体参见 <a href="https://github.com/kubernetes-incubator/kubespray/issues/2108" target="_blank" rel="noopener">kubespray issue</a> 以及 <a href="https://github.com/kubernetes/kubeadm/blob/master/docs/design/design_v1.9.md#mark-master" target="_blank" rel="noopener">官方设计文档</a></strong></p><p>很多人可能会发现大约 1 小时候 <code>kubectl get csr</code> 看不到任何 csr 了，这是因为最新版本增加了 csr 清理功能，<strong>默认对于 <code>approved</code> 和 <code>denied</code> 状态的 csr 一小时后会被清理，对于 <code>pending</code> 状态的 csr 24 小时后会被清理，想问时间从哪来的请看 <a href="https://github.com/kubernetes/kubernetes/blob/fa85bf7094a8a503fede964b7038eed51360ffc7/pkg/controller/certificates/cleaner/cleaner.go#L47" target="_blank" rel="noopener">代码</a>；PR issue 我忘记了，增加这个功能的起因大致就是因为当开启了证书轮换后，csr 会不断增加，所以需要增加一个清理功能</strong></p><h4 id="9-2、异常及警告说明"><a href="#9-2、异常及警告说明" class="headerlink" title="9.2、异常及警告说明"></a>9.2、异常及警告说明</h4><p>在部署过程中我记录了一些异常警告等，以下做一下统一说明</p><div class="hljs"><pre><code class="hljs sh"><span class="hljs-comment"># https://github.com/kubernetes/kubernetes/issues/42158</span>
<span class="hljs-comment"># 这个问题还没解决，PR 没有合并被关闭了，可以关注一下上面这个 issue，被关闭的 PR 在下面</span>
<span class="hljs-comment"># https://github.com/kubernetes/kubernetes/pull/49567</span>
Failed to update statusUpdateNeeded field <span class="hljs-keyword">in</span> actual state of world: Failed to <span class="hljs-built_in">set</span> statusUpdateNeeded to needed <span class="hljs-literal">true</span>, because nodeName=...

<span class="hljs-comment"># https://github.com/kubernetes/kubernetes/issues/59993</span>
<span class="hljs-comment"># 这个似乎已经解决了，没时间测试，PR 地址在下面，我大致 debug 一下 好像是 cAdvisor 的问题</span>
<span class="hljs-comment"># https://github.com/opencontainers/runc/pull/1722</span>
Failed to get system container stats <span class="hljs-keyword">for</span> <span class="hljs-string">"/kubepods"</span>: failed to get cgroup stats <span class="hljs-keyword">for</span> <span class="hljs-string">"/kubepods"</span>: failed to get container info <span class="hljs-keyword">for</span> <span class="hljs-string">"/kubepods"</span>: unknown containe <span class="hljs-string">"/kubepods"</span>

<span class="hljs-comment"># https://github.com/kubernetes/kubernetes/issues/58217</span>
<span class="hljs-comment"># 注意: 这个问题现在仍未解决，可关注上面的 issue，这个问题可能影响 node image gc</span>
<span class="hljs-comment"># 强烈依赖于 kubelet 做 宿主机 image gc 的需要注意一下</span>
Image garbage collection failed once. Stats initialization may not have completed yet: failed to get imageFs info: unable to find data <span class="hljs-keyword">for</span> container /

<span class="hljs-comment"># 没找到太多资料，不过感觉跟上面问题类似</span>
failed to construct signal: <span class="hljs-string">"allocatableMemory.available"</span> error: system container <span class="hljs-string">"pods"</span> not found <span class="hljs-keyword">in</span> metrics</code></pre></div></div><hr><div><div class="post-metas mb-3"><div class="post-meta mr-3"><i class="iconfont icon-category"></i> <a class="hover-with-bg" href="/categories/kubernetes/">Kubernetes</a></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a class="hover-with-bg" href="/tags/kubernetes/">Kubernetes</a></div></div><p class="note note-warning">本博客所有文章除特别声明外，均采用 <a rel="license noopener" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 国际许可协议进行许可，转载请注明出处。</p><div class="post-prevnext row"><article class="post-prev col-6"><a href="/2018/05/11/add-commit-message-style-check-to-your-gitlab/"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">为你的 GitLab 增加提交信息检测</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"> <a href="/2018/03/30/set-up-drone-ci/"><span class="hidden-mobile">Drone CI 搭建</span> <span class="visible-mobile">下一篇</span><i class="iconfont icon-arrowright"></i></a></article></div></div><article class="comments" id="comments"><div class="disqus" style="width:100%"><div id="disqus_thread"></div><script type="text/javascript">var disqus_config=function(){this.page.url="https://mritd.com/2018/04/19/set-up-kubernetes-1.10.1-cluster-by-hyperkube/",this.page.identifier="/2018/04/19/set-up-kubernetes-1.10.1-cluster-by-hyperkube/"};function loadDisqus(){var e,t;e=document,(t=e.createElement("script")).src="//bleem.disqus.com/embed.js",t.setAttribute("data-timestamp",new Date),(e.head||e.body).appendChild(t)}waitElementVisible("disqus_thread",loadDisqus)</script><noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" target="_blank" rel="nofollow noopener noopener">comments powered by Disqus.</a></noscript></div></article></article></div></div></div><div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div id="tocbot"></div></div></div></div></div></main><a id="scroll-top-button" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4> <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"> <span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"> <input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div><footer class="mt-5"><div class="text-center py-3"><div> <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a><i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div></div></footer><script src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js"></script><script src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js"></script><script src="/js/debouncer.js"></script><script src="/js/main.js"></script><script src="/js/lazyload.js"></script><script defer="defer" src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js"></script><script src="/js/clipboard-use.js"></script><script src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js"></script><script>$(document).ready(function(){var t=$("#board-ctn").offset().top;tocbot.init({tocSelector:"#tocbot",contentSelector:"#post-body",headingSelector:"h1,h2,h3,h4,h5,h6",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",collapseDepth:3,scrollSmooth:!0,headingsOffset:-t}),0<$(".toc-list-item").length&&$("#toc").css("visibility","visible")})</script><script src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js"></script><script>var typed=new Typed("#subtitle",{strings:["  ","Kubernetes 1.10.1 集群搭建&nbsp;"],cursorChar:"_",typeSpeed:80,loop:!1});typed.stop(),$(document).ready(function(){$(".typed-cursor").addClass("h2"),typed.start()})</script><script src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js"></script><script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
      icon: "❡"
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script><script src="/js/local-search.js"></script><script>var path="/local-search.xml",inputArea=document.querySelector("#local-search-input");inputArea.onclick=function(){searchFunc(path,"local-search-input","local-search-result"),this.onclick=null}</script><script src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js"></script><link rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css"><script>$("#post img:not(.no-zoom img, img[no-zoom]), img[zoom]").each(function(){var t=document.createElement("a");$(t).attr("data-fancybox","images"),$(t).attr("href",$(this).attr("src")),$(this).wrap(t)})</script></body></html>