<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png"><link rel="icon" href="/img/favicon.ico"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests"><meta name="theme-color" content="#2f4154"><meta name="author" content="Kovacs"><meta name="keywords" content="Ceph"><meta name="description" content="Ceph 是一个符合POSIX、开源的分布式存储系统；其具备了极好的可靠性、统一性、鲁棒性；经过近几年的发展，Ceph 开辟了一个全新的数据存储途径。Ceph 具备了企业级存储的分布式、可大规模扩展、没有单点故障等特点，越来越受到人们青睐；以下记录了 Ceph 的相关学习笔记。"><meta property="og:type" content="article"><meta property="og:title" content="Ceph 笔记(一)"><meta property="og:url" content="https://mritd.com/2017/05/27/ceph-note-1/index.html"><meta property="og:site_name" content="Kovacs"><meta property="og:description" content="Ceph 是一个符合POSIX、开源的分布式存储系统；其具备了极好的可靠性、统一性、鲁棒性；经过近几年的发展，Ceph 开辟了一个全新的数据存储途径。Ceph 具备了企业级存储的分布式、可大规模扩展、没有单点故障等特点，越来越受到人们青睐；以下记录了 Ceph 的相关学习笔记。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://cdn.oss.link/markdown/o8gct.jpg"><meta property="og:image" content="https://cdn.oss.link/markdown/fh5z8.jpg"><meta property="article:published_time" content="2017-05-26T17:17:19.000Z"><meta property="article:modified_time" content="2017-05-26T17:17:19.000Z"><meta property="article:author" content="Kovacs"><meta property="article:tag" content="Linux"><meta property="article:tag" content="Ceph"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="https://cdn.oss.link/markdown/o8gct.jpg"><meta name="twitter:creator" content="@kovacs_orz"><meta name="twitter:site" content="https://twitter.com/kovacs_orz"><title>Ceph 笔记(一) - Kovacs</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"mritd.com",root:"/",version:"1.9.7",typing:{enable:!0,typeSpeed:80,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"right",visible:"hover",icon:"❡"},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!0,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:3},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,follow_dnt:!0,baidu:null,google:{measurement_id:"G-H06NPECR0Z"},tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml",include_content_in_search:!0};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><script async>Fluid.ctx.dnt||Fluid.utils.createScript("https://www.googletagmanager.com/gtag/js?id=G-H06NPECR0Z",(function(){function a(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],a("js",new Date),a("config","G-H06NPECR0Z")}))</script><meta name="generator" content="Hexo 7.0.0"><link rel="alternate" href="/atom.xml" title="Kovacs" type="application/atom+xml">
<link rel="alternate" href="/rss.xml" title="Kovacs" type="application/rss+xml">
</head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>Kovacs</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/" target="_self"><i class="iconfont icon-home-fill"></i> <span>首页</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/" target="_self"><i class="iconfont icon-archive-fill"></i> <span>归档</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/" target="_self"><i class="iconfont icon-category-fill"></i> <span>分类</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/" target="_self"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></li><li class="nav-item"><a class="nav-link" href="/about/" target="_self"><i class="iconfont icon-user-fill"></i> <span>关于</span></a></li><li class="nav-item"><a class="nav-link" href="/friends/" target="_self"><i class="iconfont icon-link-fill"></i> <span>友链</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/default.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="Ceph 笔记(一)"></span></div><div class="mt-3"><span class="post-meta mr-2"><i class="iconfont icon-author" aria-hidden="true"></i> Kovacs </span><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2017-05-27 01:17" pubdate>2017年5月27日 凌晨</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 2.4k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 21 分钟</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 id="seo-header">Ceph 笔记(一)</h1><div class="markdown-body"><blockquote><p>Ceph 是一个符合POSIX、开源的分布式存储系统；其具备了极好的可靠性、统一性、鲁棒性；经过近几年的发展，Ceph 开辟了一个全新的数据存储途径。Ceph 具备了企业级存储的分布式、可大规模扩展、没有单点故障等特点，越来越受到人们青睐；以下记录了 Ceph 的相关学习笔记。</p></blockquote><h3 id="一、-Ceph-Quick-Start"><a href="#一、-Ceph-Quick-Start" class="headerlink" title="一、 Ceph Quick Start"></a>一、 Ceph Quick Start</h3><h4 id="1-1、安装前准备"><a href="#1-1、安装前准备" class="headerlink" title="1.1、安装前准备"></a>1.1、安装前准备</h4><blockquote><p>本文以 Centos 7 3.10 内核为基础环境，节点为 4 台 Vagrant 虚拟机；Ceph 版本为 Jewel.</p></blockquote><p>首先需要一台部署节点，这里使用的是宿主机；在部署节点上需要安装一些部署工具，如下</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 安装 EPEL 源</span><br>yum install -y epel-release<br><br><span class="hljs-comment"># 添加 ceph 官方源</span><br><span class="hljs-built_in">cat</span> &lt;&lt; <span class="hljs-string">EOF &gt;&gt; /etc/yum.repos.d/ceph.repo</span><br><span class="hljs-string">[ceph-noarch]</span><br><span class="hljs-string">name=Ceph noarch packages</span><br><span class="hljs-string">baseurl=https://download.ceph.com/rpm-jewel/el7/noarch</span><br><span class="hljs-string">enabled=1</span><br><span class="hljs-string">gpgcheck=1</span><br><span class="hljs-string">type=rpm-md</span><br><span class="hljs-string">gpgkey=https://download.ceph.com/keys/release.asc</span><br><span class="hljs-string">EOF</span><br><br><span class="hljs-comment"># 安装部署工具</span><br>yum update -y &amp;&amp; yum install ceph-deploy -y<br></code></pre></td></tr></table></figure><p><strong>同时，ceph-deploy 工具需要使用 ssh 来自动化部署 Ceph 各个组件，因此需要保证部署节点能够免密码登录待部署节点；最后，待部署节点最好加入到部署节点的 hosts 中，方便使用域名(某些地方强制)连接管理</strong></p><h4 id="1-2、校对时钟"><a href="#1-2、校对时钟" class="headerlink" title="1.2、校对时钟"></a>1.2、校对时钟</h4><p>由于 Ceph 采用 Paxos 算法保证数据一致性，所以安装前需要先保证各个节点时钟同步</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 安装 ntp 工具</span><br>yum install ntp ntpdate ntp-doc -y<br><span class="hljs-comment"># 校对系统时钟</span><br>ntpdate 0.cn.pool.ntp.org<br></code></pre></td></tr></table></figure><h4 id="1-3、创建集群配置"><a href="#1-3、创建集群配置" class="headerlink" title="1.3、创建集群配置"></a>1.3、创建集群配置</h4><p>ceph-deploy 工具部署集群前需要创建一些集群配置信息，其保存在 <code>ceph.conf</code> 文件中，这个文件未来将会被复制到每个节点的 <code>/etc/ceph/ceph.conf</code></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 创建集群配置目录</span><br><span class="hljs-built_in">mkdir</span> ceph-cluster &amp;&amp; <span class="hljs-built_in">cd</span> ceph-cluster<br><span class="hljs-comment"># 创建 monitor-node</span><br>ceph-deploy new docker1<br><span class="hljs-comment"># 追加 OSD 副本数量(测试虚拟机总共有3台)</span><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;osd pool default size = 3&quot;</span> &gt;&gt; ceph.conf<br></code></pre></td></tr></table></figure><h4 id="1-4、创建集群"><a href="#1-4、创建集群" class="headerlink" title="1.4、创建集群"></a>1.4、创建集群</h4><p>创建集群使用 ceph-deploy 工具即可</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 安装 ceph</span><br>ceph-deploy install docker1 docker2 docker3<br><span class="hljs-comment"># 初始化 monitor node 和 秘钥文件</span><br>ceph-deploy mon create-initial<br><span class="hljs-comment"># 在两个 osd 节点创建一个目录作为 osd 存储</span><br><span class="hljs-built_in">mkdir</span> /data<br><span class="hljs-built_in">chown</span> -R ceph:ceph /data<br><span class="hljs-comment"># 初始化 osd</span><br>ceph-deploy osd prepare docker1:/data docker2:/data docker3:/data<br><span class="hljs-comment"># 激活 osd</span><br>ceph-deploy osd activate docker1:/data docker2:/data docker3:/data<br><span class="hljs-comment"># 部署 ceph cli 工具和秘钥文件</span><br>ceph-deploy admin docker1 docker2 docker3<br><span class="hljs-comment"># 确保秘钥有读取权限</span><br><span class="hljs-built_in">chmod</span> +r /etc/ceph/ceph.client.admin.keyring<br><span class="hljs-comment"># 检测集群状态</span><br>ceph health<br></code></pre></td></tr></table></figure><p>执行 <code>ceph health</code> 命令后应当返回 <code>HEALTH_OK</code>；如出现 <code>HEALTH_WARN clock skew detected on mon.docker2; Monitor clock skew detected</code>，说明时钟不同步，手动同步时钟稍等片刻后即可；其他错误可以通过如下命令重置集群重新部署</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh">ceph-deploy purge &#123;ceph-node&#125; [&#123;ceph-node&#125;]<br>ceph-deploy purgedata &#123;ceph-node&#125; [&#123;ceph-node&#125;]<br>ceph-deploy forgetkeys<br></code></pre></td></tr></table></figure><p><strong>更多细节，如防火墙、SELinux配置等请参考 <a target="_blank" rel="noopener" href="http://docs.ceph.com/docs/master/start/quick-start-preflight/#rhel-centos">官方文档</a></strong></p><h4 id="1-5、其他组件创建"><a href="#1-5、其他组件创建" class="headerlink" title="1.5、其他组件创建"></a>1.5、其他组件创建</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 创建 MDS</span><br>ceph-deploy mds create docker1<br><span class="hljs-comment"># 创建 RGW</span><br>ceph-deploy rgw create docker1<br><span class="hljs-comment"># 增加 monitor</span><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;public network = 192.168.1.0/24&quot;</span> &gt;&gt; ceph.conf<br>ceph-deploy --overwrite-conf mon create docker2 docker3<br><span class="hljs-comment"># 查看仲裁信息</span><br>ceph quorum_status --format json-pretty<br></code></pre></td></tr></table></figure><h3 id="二、Ceph-组件及测试"><a href="#二、Ceph-组件及测试" class="headerlink" title="二、Ceph 组件及测试"></a>二、Ceph 组件及测试</h3><h4 id="2-1、Ceph-架构图"><a href="#2-1、Ceph-架构图" class="headerlink" title="2.1、Ceph 架构图"></a>2.1、Ceph 架构图</h4><p>以下图片(摘自网络)展示了基本的 Ceph 架构</p><p><img src="https://cdn.oss.link/markdown/o8gct.jpg" srcset="/img/loading.gif" lazyload alt="ceph 架构"></p><ul><li>OSD: Ceph 实际存储数据单元被称为 OSD，OSD 可以使用某个物理机的目录、磁盘设备，甚至是 RAID 阵列；</li><li>MON: 在 OSD 之上则分布着多个 MON(monitor)，Ceph 集群内组件的状态信息等被维护成一个个 map，而 MON 则负责维护集群所有组件 map 信息，各个集群内组件心跳请求 MON 以确保其 map 保持最新状态；当集群发生故障时，Ceph 将采用 Paxos 算法保证数据一致性，这其中仲裁等主要由 MON 完成，所以 MON 节点建议最少为 3 个，并且为奇数以防止脑裂情况的发生；</li><li>MDS: Ceph 本身使用对象形式存储数据，而对于外部文件系统访问支持则提供了上层的 CephFS 接口；CephFS 作为文件系统接口则需要一些元数据，这些原数据就存放在 MDS 中；目前 Ceph 只支持单个 MDS 工作，<strong>但是可以通过设置 MDS 副本，以保证 MDS 的可靠性</strong></li><li>RADOS: RADOS 全称 Reliable Autonomic Distributed Object Store，即可靠分布式对象存储；其作为在整个 Ceph 集群核心基础设施，向外部提供基本的数据操作</li><li>librados: 为了支持私有云等程序调用，Ceph 提供了 C 实现的 API 库 librados，librados 可以支持主流编程语言直接调用，沟通 RADOS 完成数据存取等操作</li><li>RBD: RDB 个人理解是一个命令行工具，一般位于宿主机上，通过该工具可以直接跟 librados 交互，实现创建存储对象，格式化 Ceph 块设备等操作</li><li>RADOS GW: 从名字可以看出来，这个组件是一个代理网关，通过 RADOS GW 可以将 RADOS 响应转化为 HTTP 响应，同样可以将外部 HTTP 请求转化为 RADOS 调用；RADOS GW 主要提供了三大功能: <strong>兼容 S3 接口、兼容 Swift 接口、提供管理 RestFul API</strong></li></ul><p>下图(摘自网络)从应用角度描述了 Ceph 架构</p><p><img src="https://cdn.oss.link/markdown/fh5z8.jpg" srcset="/img/loading.gif" lazyload alt="APP Ceph 架构"></p><h4 id="2-2、对象存储测试"><a href="#2-2、对象存储测试" class="headerlink" title="2.2、对象存储测试"></a>2.2、对象存储测试</h4><p>此处直接上代码</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 创建测试文件</span><br><span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero of=<span class="hljs-built_in">test</span> bs=1G count=1<br><span class="hljs-comment"># 创建对象存储池</span><br>rados mkpool data<br><span class="hljs-comment"># 放入对象</span><br>rados put test-file <span class="hljs-built_in">test</span> --pool=data<br><span class="hljs-comment"># 检查存储池</span><br>rados -p data <span class="hljs-built_in">ls</span><br><span class="hljs-comment"># 检查对象信息</span><br>ceph osd map data test-file<br><span class="hljs-comment"># 删除对象</span><br>rados -p data <span class="hljs-built_in">rm</span> test-file<br><span class="hljs-comment"># 删除存储池(存储池写两遍并且加上确认)</span><br>rados rmpool data data --yes-i-really-really-mean-it<br></code></pre></td></tr></table></figure><h4 id="2-3、块设备测试"><a href="#2-3、块设备测试" class="headerlink" title="2.3、块设备测试"></a>2.3、块设备测试</h4><p><strong>官方文档中提示，使用 rdb 的客户端不建议与 OSD 等节点在同一台机器上</strong></p><blockquote><p>You may use a virtual machine for your ceph-client node, but do not execute the following procedures on the same physical node as your Ceph Storage Cluster nodes (unless you use a VM). See FAQ for details.</p></blockquote><p>这里从第四台虚拟机上执行操作，首先安装所需客户端工具</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 部署节点上 ceph-cluster 目录下执行</span><br>ceph-deploy install docker4<br>ceph-deploy admin docker4<br></code></pre></td></tr></table></figure><p>然后创建块设备</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 块设备单位为 MB</span><br>rbd create data --size 10240<br><span class="hljs-comment"># 映射块设备</span><br>map foo --name client.admin<br></code></pre></td></tr></table></figure><p><strong>在上面的 map 映射操作时，可能出现如下错误</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">RBD image feature <span class="hljs-built_in">set</span> mismatch. You can <span class="hljs-built_in">disable</span> features unsupported by the kernel with <span class="hljs-string">&quot;rbd feature disable&quot;</span><br></code></pre></td></tr></table></figure><p>查看系统日志可以看到如下输出</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh">➜  ~ dmesg | <span class="hljs-built_in">tail</span><br>[-1127592253.530346] rbd: image data: image uses unsupported features: 0x38<br>[-1127590337.563180] libceph: mon0 192.168.1.11:6789 session established<br>[-1127590337.563741] libceph: client4200 fsid dd9fdfee-438a-47aa-be21-114372bc1f44<br></code></pre></td></tr></table></figure><p><strong>问题原因: 在 Ceph 高版本进行 map image 时，默认 Ceph 在创建 image(上文 data)时会增加许多 features，这些 features 需要内核支持，在 Centos7 的内核上支持有限，所以需要手动关掉一些 features</strong></p><p>首先使用 <code>rbd info data</code> 命令列出创建的 image 的 features</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sh">rbd image <span class="hljs-string">&#x27;data&#x27;</span>:<br>        size 10240 MB <span class="hljs-keyword">in</span> 2560 objects<br>        order 22 (4096 kB objects)<br>        block_name_prefix: rbd_data.37c6238e1f29<br>        format: 2<br>        features: layering, exclusive-lock, object-map, fast-diff, deep-flatten<br>        flags:<br></code></pre></td></tr></table></figure><p>在 features 中我们可以看到默认开启了很多:</p><ul><li>layering: 支持分层</li><li>striping: 支持条带化 v2</li><li>exclusive-lock: 支持独占锁</li><li>object-map: 支持对象映射(依赖 exclusive-lock)</li><li>fast-diff: 快速计算差异(依赖 object-map)</li><li>deep-flatten: 支持快照扁平化操作</li><li>journaling: 支持记录 IO 操作(依赖独占锁）</li></ul><p><strong>而实际上 Centos 7 的 3.10 内核只支持 layering… 所以我们要手动关闭一些 features，然后重新 map；如果想要一劳永逸，可以在 ceph.conf 中加入 <code>rbd_default_features = 1</code> 来设置默认 features(数值仅是 layering 对应的 bit 码所对应的整数值)。</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 关闭不支持特性</span><br>rbd feature <span class="hljs-built_in">disable</span> data exclusive-lock, object-map, fast-diff, deep-flatten<br><span class="hljs-comment"># 重新映射</span><br>rbd map data --name client.admin<br><span class="hljs-comment"># 成功后返回设备位置</span><br>/dev/rbd0<br></code></pre></td></tr></table></figure><p><strong>最后我们便可以格式化正常挂载这个设备了</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs sh">➜  ~ mkfs.xfs /dev/rbd0<br>meta-data=/dev/rbd0              isize=512    agcount=17, agsize=162816 blks<br>         =                       sectsz=512   attr=2, projid32bit=1<br>         =                       crc=1        finobt=0, sparse=0<br>data     =                       bsize=4096   blocks=2621440, imaxpct=25<br>         =                       sunit=1024   swidth=1024 blks<br>naming   =version 2              bsize=4096   ascii-ci=0 ftype=1<br><span class="hljs-built_in">log</span>      =internal <span class="hljs-built_in">log</span>           bsize=4096   blocks=2560, version=2<br>         =                       sectsz=512   sunit=8 blks, lazy-count=1<br>realtime =none                   extsz=4096   blocks=0, rtextents=0<br>➜  ~ <span class="hljs-built_in">mkdir</span> test1<br>➜  ~ mount /dev/rbd0 test1<br><span class="hljs-comment"># 写入测试</span><br>➜  ~ <span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero of=test1/test-file bs=1G count=1<br>记录了1+0 的读入<br>记录了1+0 的写出<br>1073741824字节(1.1 GB)已复制，16.3689 秒，65.6 MB/秒<br>➜  ~ <span class="hljs-built_in">ls</span> test1<br>test-file<br></code></pre></td></tr></table></figure><h4 id="2-4、CephFS-测试"><a href="#2-4、CephFS-测试" class="headerlink" title="2.4、CephFS 测试"></a>2.4、CephFS 测试</h4><p>在测试 CephFS 之前需要先创建两个存储池和一个 fs，创建存储池要指定 PG 数量</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh">ceph osd pool create cephfs_data 32<br>ceph osd pool create cephfs_metadata 32<br>ceph fs new testfs cephfs_metadata cephfs_data<br></code></pre></td></tr></table></figure><p><strong>PG 概念:</strong></p><blockquote><p>当 Ceph 集群接收到存储请求时，Ceph 会将其分散到各个 PG 中，PG 是一组对象的逻辑集合；根据 Ceph 存储池的复制级别，每个 PG的数据会被复制并分发到集群的多个 OSD 上；一般来说增加 PG 数量能降低 OSD 负载，一般每个 OSD 大约分配 50 ~ 100 PG，<strong>关于 PG 数量一般遵循以下公式</strong></p></blockquote><ul><li>集群 PG 总数 &#x3D; (OSD 总数 * 100) &#x2F; 数据最大副本数</li><li>单个存储池 PG 数 &#x3D; (OSD 总数 * 100) &#x2F; 数据最大副本数 &#x2F;存储池数</li></ul><p><strong>注意，PG 最终结果应当为最接近以上计算公式的 2 的 N 次幂(向上取值)；如我的虚拟机环境每个存储池 PG 数 &#x3D; <code>3(OSD) * 100 / 3(副本) / 5(大约 5 个存储池) = 20</code>，向上取 2 的 N 次幂 为 32</strong></p><p>挂载 CephFS 一般有两种方式，一种是使用内核驱动挂载，一种是使用 <code>ceph-fuse</code> 用户空间挂载；内核方式挂载需要提取 Ceph 管理 key，如下</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># key 在 ceph.conf 中</span><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;AQB37CZZblBkDRAAUrIrRGsHj/NqdKmVlMQ7ww==&quot;</span> &gt; ceph-key<br><span class="hljs-comment"># 创建目录挂载</span><br><span class="hljs-built_in">mkdir</span> test2<br>mount -t ceph 192.168.1.11:6789:/ /root/test2 -o name=admin,secretfile=ceph-key<br><span class="hljs-comment"># 写入测试</span><br>➜  ~ <span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero of=test2/testFs bs=1G count=1<br>记录了1+0 的读入<br>记录了1+0 的写出<br>1073741824字节(1.1 GB)已复制，6.83251 秒，157 MB/秒<br></code></pre></td></tr></table></figure><p>使用 ceph-fuse 用户空间挂载方式比较简单，但需要先安装 <code>ceph-fuse</code> 软件包</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 安装 ceph-fuse</span><br>yum install -y ceph-fuse<br><span class="hljs-comment"># 挂载</span><br><span class="hljs-built_in">mkdir</span> test3<br>ceph-fuse -m 192.168.1.11:6789 test3<br><span class="hljs-comment"># 写入测试</span><br>➜  ~ <span class="hljs-built_in">dd</span> <span class="hljs-keyword">if</span>=/dev/zero of=test3/testFs bs=1G count=1<br>记录了1+0 的读入<br>记录了1+0 的写出<br>1073741824字节(1.1 GB)已复制，8.18417 秒，131 MB/秒<br></code></pre></td></tr></table></figure><h4 id="2-5、对象网关测试"><a href="#2-5、对象网关测试" class="headerlink" title="2.5、对象网关测试"></a>2.5、对象网关测试</h4><p>对象网关在 <strong>1.5、其他组件创建</strong> 部分已经做了创建(RGW)，此时直接访问 <code>http://ceph-node-ip:7480</code> 返回如下</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">ListAllMyBucketsResult</span> <span class="hljs-attr">xmlns</span>=<span class="hljs-string">&quot;http://s3.amazonaws.com/doc/2006-03-01/&quot;</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">Owner</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">ID</span>&gt;</span>anonymous<span class="hljs-tag">&lt;/<span class="hljs-name">ID</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">DisplayName</span>/&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">Owner</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">Buckets</span>/&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">ListAllMyBucketsResult</span>&gt;</span><br></code></pre></td></tr></table></figure><p>这就说明网关已经 ok，由于手里没有能读写测试工具，这里暂不做过多说明</p><p><strong>本文主要参考 <a target="_blank" rel="noopener" href="http://docs.ceph.com/docs/master/start/">Ceph 官方文档 Quick Start</a> 部分，如有其它未说明到的细节可从官方文档获取</strong></p></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/linux/" class="category-chain-item">Linux</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/linux/" class="print-no-link">#Linux</a> <a href="/tags/ceph/" class="print-no-link">#Ceph</a></div></div><div class="license-box my-3"><div class="license-title"><div>Ceph 笔记(一)</div><div>https://mritd.com/2017/05/27/ceph-note-1/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>Kovacs</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2017年5月27日</div></div><div class="license-meta-item"><div>许可协议</div><div><a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i> </span></a><a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><span class="hint--top hint--rounded" aria-label="NC - 非商业性使用"><i class="iconfont icon-nc"></i> </span></a><a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><span class="hint--top hint--rounded" aria-label="SA - 相同方式共享"><i class="iconfont icon-sa"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/2017/05/30/ceph-note-2/" title="Ceph 笔记(二)"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">Ceph 笔记(二)</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2017/05/12/docker-uses-the-host-network-segment-ip/" title="Docker 分配宿主机网段 IP"><span class="hidden-mobile">Docker 分配宿主机网段 IP</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article id="comments" lazyload><div class="disqus" style="width:100%"><div id="disqus_thread"></div><script type="text/javascript">var disqus_config=function(){this.page.url="https://mritd.com/2017/05/27/ceph-note-1/",this.page.identifier="/2017/05/27/ceph-note-1/"};Fluid.utils.loadComments("#disqus_thread",(function(){var e=document,t=e.createElement("script");t.src="//bleem.disqus.com/embed.js",t.setAttribute("data-timestamp",new Date),(e.head||e.body).appendChild(t)}))</script><noscript>Please enable JavaScript to view the comments</noscript></div></article></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>目录</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> <i class="iconfont icon-docker"></i> <a href="https://bandwagonhost.com/aff.php?aff=61367" target="_blank" rel="nofollow noopener"><span>BandwagonHost</span></a></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!0,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var i=jQuery("#board-ctn").offset().top;window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-i},CONFIG.toc)),t.find(".toc-list-item").length>0&&t.css("visibility","visible"),Fluid.events.registerRefreshCallback((function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback((function(){if("anchors"in window){anchors.removeAll();var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}}))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script src="/js/local-search.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript></body></html>